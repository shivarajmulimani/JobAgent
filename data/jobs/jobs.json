[
    {
        "id":"gd-1009653283335",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009653283335",
        "job_url_direct":null,
        "title":"Data Engineer",
        "company":"Hewlett Packard Enterprise",
        "location":"Bengaluru",
        "date_posted":1740614400000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":420000.0,
        "max_amount":500000.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"Data Engineer  \n\n\nThis role has been designed as \u2018\u2019Onsite\u2019 with an expectation that you will primarily work from an HPE office.**Who We Are:**\n\n\nHewlett Packard Enterprise is the global edge\\-to\\-cloud company advancing the way people live and work. We help companies connect, protect, analyze, and act on their data and applications wherever they live, from edge to cloud, so they can turn insights into outcomes at the speed required to thrive in today\u2019s complex world. Our culture thrives on finding new and better ways to accelerate what\u2019s next. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good. If you are looking to stretch and grow your career our culture will embrace you. Open up opportunities with HPE.\n\n**Job Description:**\n\n ***Job Family Definition:***\n\n\nwe are looking for a Software Engineer to join us! In this amazing role, you will be responsible for design, development, troubleshooting and debugging of data engineering products, Software Defined Storage analytics products of HPE. This is an amazing opportunity to be part of our R\\&D team and work in areas of storage, filesystem, hyper converged solutions and analytics. You will evaluate, design, and define coding, programming, and integration activities based on objectives and established project guidelines, collaborating with product management to understand and finalize requirements.\n\n**What You'll Do:**\n\n* we are looking for a Software Engineer to join us! In this amazing role, you will be responsible for design, development, troubleshooting and debugging of data engineering products, Software Defined Storage analytics products of HPE. This is an amazing opportunity to be part of our R\\&D team and work in areas of storage, filesystem, hyper converged solutions and analytics. You will evaluate, design, and define coding, programming, and integration activities based on objectives and established project guidelines, collaborating with product management to understand and finalize requirements.\n\n**What you need to bring:**\n\n* Bachelor's degree in Computer Science, or another data\\-oriented discipline\n* 4 to 12 years of industry experience as data scientist\n* Expert in Python coding\n* Statistical inference (hypothesis testing, estimation with confidence intervals, Bayesian inference)\n* Fluent user of Apache Spark\n* Working knowledge of data structures (array, maps, trees, stacks, queues) and algorithms (recursion, dynamic programming, backtracking)\n* Descriptive statistics Knowledge (central tendency, variability, distribution)\n* Clear technical communication\n* Ability and willingness to learn quickly\n\n **Additional preferred skills**\n\n* Familiar with NoSQL databases, preferably Cassandra\n* Knowledge in Scala, Rust\n* Familiar with Kubernetes, Docker, Git, Maven\n* Gen AI, Knowledge about foundational LLM models.\n\n**Additional Skills:**\n\n\nCloud Architectures, Cross Domain Knowledge, Design Thinking, Development Fundamentals, DevOps, Distributed Computing, Microservices Fluency, Full Stack Development, Release Management, Security\\-First Mindset, User Experience (UX)**What We Can Offer You:**\n\n**Health \\& Wellbeing**\n\n\nWe strive to provide our team members and their loved ones with a comprehensive suite of benefits that supports their physical, financial and emotional wellbeing.\n\n**Personal \\& Professional Development**\n\n\nWe also invest in your career because the better you are, the better we all are. We have specific programs catered to helping you reach any career goals you have \u2014 whether you want to become a knowledge expert in your field or apply your skills to another division.\n\n**Diversity, Inclusion \\& Belonging**\n\n\nWe are unconditionally inclusive in the way we work and celebrate individual uniqueness. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good.\n\n**Let's Stay Connected:**\n\n\nFollow @HPECareers on Instagram to see the latest on people, culture and tech at HPE.\n\n\n\\#india\n\\#aruba**Job:**\n\n\nEngineering**Job Level:**\n\n\nTCP\\_04  \n\nHPE is an Equal Employment Opportunity\/ Veterans\/Disabled\/LGBT and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made on the basis of qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together. Please click here: Equal Employment Opportunity.\n\n**Hewlett Packard Enterprise is EEO F\/M\/Protected Veteran\/ Individual with Disabilities.**\n\n  \n\nHPE will comply with all applicable laws related to employer use of arrest and conviction records, including laws requiring employers to consider for employment qualified applicants with criminal histories.",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE1093046.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/1093046\/hewlett-packard-enterprise-squarelogo-1446452961178.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009653053915",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009653053915",
        "job_url_direct":null,
        "title":"Data Engineer (Django, Python)",
        "company":"Bluewings",
        "location":"India",
        "date_posted":1740614400000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"monthly",
        "min_amount":40000.0,
        "max_amount":70000.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"**Key Details:**\n\n* Location: Bangalore\\-Onsite\n* Type\\- Work From Office\\-Bangalore E\\-city\n\n**Job Description:**\n\nWe are seeking a skilled **Data Engineer** with experience in **Django and Python** to join our team. The ideal candidate will have a strong background in data engineering, database management, and backend development.\n\n**Key Responsibilities:**\n\n* Design, develop, and maintain data pipelines and ETL processes.\n* Work with large datasets, ensuring data integrity and optimal performance.\n* Develop and maintain backend APIs using **Django** and **Python**.\n* Collaborate with data scientists, analysts, and other engineers to optimize data workflows.\n* Optimize database performance and ensure scalability.\n* Implement data security and compliance best practices.\n* Work with relational and NoSQL databases such as PostgreSQL, MySQL, MongoDB, or Redis.\n\n**Required Skills:**\n\n* 2 to 5 years of experience in **Python** and **Django** development.\n* Strong knowledge of **SQL** and database design principles.\n* Experience with data modeling, ETL pipelines, and data processing frameworks.\n* Proficiency in working with cloud services (AWS, GCP, or Azure) is a plus.\n* Experience with **Big Data** tools like Spark, Hadoop, or Kafka is a plus.\n* Familiarity with containerization (Docker, Kubernetes) is a plus.\n\n**Preferred Qualifications:**\n\n* Bachelor's or Master's degree in Computer Science, Data Engineering, or a related field.\n* Strong analytical and problem\\-solving skills.\n* Ability to work in a fast\\-paced and dynamic environment.\n\nInterview Process for selected candidates\n\n1\\. First Round: Conducted via Google Meet.\n\n2\\. Second Round: Technical round Face to face.\n\nhttps:\/\/www.synclovis.com\/about\\-us\/\n\nJob Type: Full\\-time\n\nPay: \u20b940,000\\.00 \\- \u20b970,000\\.00 per month\n\nBenefits:\n\n* Paid sick time\n* Provident Fund\n\nSchedule:\n\n* Day shift\n* Monday to Friday\n\nSupplemental Pay:\n\n* Performance bonus\n\nWork Location: In person",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009652908908",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009652908908",
        "job_url_direct":null,
        "title":"Senior Software Developer",
        "company":"SkyServe",
        "location":"Bengaluru",
        "date_posted":1740614400000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":1081143.0,
        "max_amount":2083502.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":"hello@skyserve.ai",
        "description":"**About Us**\n\nSkyServe is an AI and edge computing technology company for satellites and aerospace platforms enabling analytics providers and core industries to deploy applications for earth observation and space based solutions.\n\nSkyServe seeks dynamic individuals for the position of Senior Software Developer to contribute to their innovative team based in Bengaluru.**Senior Software Developer**\n\n**Location: Bengaluru, India**\n\n**Experience Level: 5\\+ Years**\n\n**About the Role**\n\n**We are seeking a Senior Software Developer with expertise in backend systems, machine learning, and scalable architecture to design and build high\\-impact products. The ideal candidate should have experience handling large\\-scale distributed systems, leading teams, and working with modern cloud technologies.**\n\n**Key Responsibilities**\n\n* Design and develop high\\-performance backend systems handling millions of requests per day.\n* Work with Azure Databricks and PySpark to process large\\-scale datasets efficiently.\n* Lead and mentor a team of engineers, ensuring best coding practices.\n* Collaborate with data scientists, product managers, and cloud engineers to develop end\\-to\\-end solutions.\n* Architect and implement cloud\\-native, high\\-availability systems with a focus on security and performance.\n* Optimize algorithms and integrate computer vision models into embedded platforms.\n* Represent SkyServe in technical conferences and knowledge\\-sharing sessions.\n\n**Required Skills \\& Qualifications**\n\n* Bachelor's or Master\u2019s degree in Computer Science, Electrical Engineering, or a related field.\n* Proficiency in Python for backend development.\n* Strong understanding of embedded systems, hardware\\-software interaction, and memory management.\n* Experience leading teams and working in agile, fast\\-paced environments.\n* Excellent problem\\-solving, communication, and collaboration skills.\n\n**Preferred Qualifications**\n\n* Experience with **Geo\\-AI, geospatial data**.\n* Hands\\-on experience with **full\\-stack development (JavaScript\/React)**.\n* Understanding of **Linux kernel development, and version control systems (Git)**.\n* Familiarity with Jetson hardware platforms, and deep learning frameworks (TensorFlow\/PyTorch).\n* Background in **data science, cloud\\-hosted products, or geospatial data**.\n* Interest in **space, satellites, or geospatial applications**.\n\nJoin us in pushing the boundaries of satellite\\-based insights and contribute to shaping the future of technology! If you're ready to make an impact, we want to hear from you. Apply now to join our innovative team at SkyServe.\n\n**Why Join Us?**\n\n* **Work on cutting\\-edge AI and geospatial technologies.**\n* **Be part of a high\\-performing engineering team solving real\\-world challenges.**\n* **Competitive salary and benefits.**\n* **Opportunities to lead and contribute to patents and publications.**\n\n**If you're passionate about building impactful software solutions, we\u2019d love to hear from you! Apply now.** \n\n**How to Apply:**\n\nIf you are passionate about role and excited about the opportunity to join a dynamic team at the forefront of innovation, please submit your resume, cover letter to hello@skyserve.ai\n\n**Only those candidates can apply who:**\n\n* are available for full\\-time (in\\-office) roles.\n* can start immediately.\n* have relevant skills and interests.\n\nJob Type: Full\\-time\n\nPay: \u20b91,081,142\\.48 \\- \u20b92,083,502\\.07 per year\n\nBenefits:\n\n* Flexible schedule\n* Food provided\n* Health insurance\n* Provident Fund\n* Work from home\n\nSchedule:\n\n* Day shift\n* Monday to Friday\n\nSupplemental Pay:\n\n* Performance bonus\n\nWork Location: In person\n\nExpected Start Date: 18\/03\/2025",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009653163169",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009653163169",
        "job_url_direct":null,
        "title":"Applied Scientist",
        "company":"Oracle",
        "location":"Bengaluru",
        "date_posted":1740614400000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"At Oracle Cloud Infrastructure (OCI), we build the future of the cloud for Enterprises as a diverse team of fellow creators and inventors. We act with the speed and attitude of a start\\-up, with the scale and customer focus of the leading enterprise software company in the world. Values are OCI\u2019s foundation and how we deliver excellence. We strive for equity, inclusion, and respect for all. We are committed to the greater good in our products and our actions. We are constantly learning and taking opportunities to grow our careers and ourselves. We challenge each other to stretch beyond our past to build our future. You are the builder here. You will be part of a team of really smart, motivated, and diverse people and given the autonomy and support to do your best work. It is a dynamic and flexible workplace where you\u2019ll belong and be encouraged.\n\n\nWithin OCI, AI Services team's one of the goals is to improve user experience and solve challenging problems through seamless employee services by enabling AI\/ML services like NLP , Vision, Machine Translation etc.\n\n\nWe are seeking a seasoned ML engineer\/developer with strong background in software development and experience in ML ops, dev ops and ML Platform. The ideal candidate will collaborate with cross functional teams to design, implement, and optimize ML Services and Platform. A successful candidate will be a person who enjoys diving deep into ML infrastructure, doing analysis, discovering root causes, and designing long\\-term solutions. You will be joining our AL infra and platform Engineering Service team who is responsible for building AI Platform, AI Ops capabilities to improve operational efficiency and effectiveness of enterprise engineering cloud services \\- thereby improve customer experience and service resiliency. So you will have an opportunity to design, implement systems end to end by helping select the right technologies, and envisioning a long\\-term architecture is part of the role. Finally, we always look for enthusiastic, passionate individuals with a willingness to learn new technologies.\n\n\nCareer Level \\- IC3\n\n\n  \nResponsibilities:\n\n\n* Build and maintain scalable ML infrastructure and platforms for managing and deploying models in production environment\n* Design, implement and optimize AI services \/ ML Engineering Platform\/Infra for Data processing , Feature Engineering , Model training and Inference\n* Implement best practices for ML Ops, Dev Ops including model versioning , monitoring , logging and automated testing\n* Proven ability to deliver products and experience with the full software development lifecycle\n* Experience working on large\\-scale, highly distributed services infrastructure\n* Translate business needs into advanced machine learning AI services and provide strong algorithm and coding execution and delivery of Machine Learning \\& Artificial Intelligence.\n* Develop analysis and optimization methods to improve the AI platform Capabilities\n* Experience working in an operational environment with mission\\-critical tier\\-one live site servicing\n* Experience designing architectures that demonstrate deep technical depth in one area, or span many products, to enable high availability, scalability, market\\-leading features and flexibility to meet future business demands\n* Stay up to date with latest advancements in machine learning , security technology and industry trends to drive innovation and maintain competitive advantage\n\n**Preferred Qualifications**\n\n* BS or MS degree in Computer Science or relevant technical field involving coding or equivalent practical experience\n* 5\\+ years of total experience in software development\n* Hands\\-on experience developing and maintaining services on a public cloud platform (e.g., AWS, Azure, Oracle)\n* Knowledge of Infrastructure as Code (IAC) languages, preferably Terraform\n* Strong proficiency in programming languages such as Python, Java and ML frameworks\/libraries such as Tensor flow , Pytorch or scikit\\-learn\n* Strong knowledge of Container and its Orchestration technology like Kubernetes, docker\n* Solid understanding of software engineering principles, including version control , testing and deployment automation\n* Communicate effectively to multiple stakeholders on value and insights from data\n* Make Recommendations and influence the AI service roadmap for our platforms \\& services to constantly improve Customer experience.\n* Mentor other ML engineers\/developer, and help them to develop their projects related to experimentation and evaluation.\n* Craft a measurement strategy to evaluate the performance of complex systems against challenging requirements\n* Develop robust methods for model monitoring in production and learning from feedback Ability to work with incomplete requirements and handle multiple projects with deadlines",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE1737.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/1737\/oracle-squarelogo-1570718316042.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009650553485",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009650553485",
        "job_url_direct":null,
        "title":"Lead - Data Engineer, Digital Business",
        "company":"Sony Pictures Networks",
        "location":"Bengaluru",
        "date_posted":1740528000000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":650000.0,
        "max_amount":1000000.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"Technology\nBengaluru (1005\\)\n\n\n**Job Description**\n\n**Organization** \u2013 Sony Pictures Networks India (SPN\n\n**Role Overview \\-** Role involves leading SonyLIV's data engineering strategy, architecting scalable data infrastructure, driving innovation in data processing, ensuring operational excellence, and fostering a high\\-performance team to enable data\\-driven insights for OTT content and user engagement.\n\n **Position Details \\-**\n\n\nRole \\- Frontend Engineering\n\n\nPosition \\- Lead \\- Data Engineering, Digital Business\n\n\nLocation \\- Bangalore\n\n\nExperience \\- \\+ years\n\n **Responsibilities**:\n\n* Define the Technical Vision for Scalable Data Infrastructure: Establish a robust technical strategy for SonyLIV\u2019s data and analytics platform, architecting a scalable, high\\-performance data ecosystem using modern technologies like Spark, Kafka, Snowflake, and cloud services (AWS\/GCP).\n* Lead Innovation in Data Processing and Architecture: Advance SonyLIV\u2019s data engineering practices by implementing real\\-time data processing, optimized ETL pipelines, and streaming analytics through tools like Apache Airflow, Spark, and Kubernetes. Enable high\\-speed data processing to support real\\-time insights for content and user engagement.\n* Ensure Operational Excellence in Data Systems: Set and enforce standards for data reliability, privacy, and performance. Define SLAs for production data processes, using monitoring tools (Grafana, Prometheus) to maintain system health and quickly resolve issues.\n* Build and Mentor a High\\-Caliber Data Engineering Team: Recruit and lead a skilled team with strengths in distributed computing, cloud infrastructure, and data security. Foster a collaborative and innovative culture, focused on technical excellence and efficiency.\n* Collaborate with Cross\\-Functional Teams: Partner closely with Data Scientists, Software Engineers, and Product Managers to deliver scalable data solutions for personalization algorithms, recommendation engines, and content analytics.\n* Architect and Manage Production Data Models and Pipelines: Design and launch production\\-ready data models and pipelines capable of supporting millions of users. Utilize advanced storage and retrieval solutions like Hive, Presto, and BigQuery to ensure efficient data access.\n* Drive Data Quality and Business Insights: Implement automated quality frameworks to maintain data accuracy and reliability. Oversee the creation of BI dashboards and data visualizations using tools like Tableau and Looker, providing actionable insights into user engagement and content performance.\n\n\nThis role offers the opportunity to lead SonyLIV\u2019s data engineering strategy, driving technological innovation and operational excellence while enabling data\\-driven decisions that shape the future of OTT entertainment.\n\n **Minimum Qualifications:**\n\n* 15\\+ years of progressive experience in data engineering, business intelligence, and data warehousing, including significant expertise in high\\-volume, real\\-time data environments.\n* Proven track record in building, scaling, and managing large data engineering teams (10\\+ members), including experience managing managers and guiding teams through complex data challenges.\n* Demonstrated success in designing and implementing scalable data architectures, with hands\\-on experience using modern data technologies (e.g., Spark, Kafka, Redshift, Snowflake, BigQuery) for data ingestion, transformation, and storage.\n* Advanced proficiency in SQL and experience with at least one object\\-oriented programming language (Python, Java, or similar) for custom data solutions and pipeline optimization.\n* Strong experience in establishing and enforcing SLAs for data availability, accuracy, and latency, with a focus on data reliability and operational excellence.\n* Extensive knowledge of A\/B testing methodologies and statistical analysis, including a solid understanding of the application of these techniques for user engagement and content analytics in OTT environments.\n* Skilled in data governance, data privacy, and compliance, with hands\\-on experience implementing security protocols and controls within large data ecosystems.\n\n **Preferred Qualifications:**\n\n* Bachelor's or Master\u2019s degree in Computer Science, Mathematics, Physics, or a related technical field.\n* Experience managing the end\\-to\\-end data engineering lifecycle, from model design and data ingestion through to visualization and reporting.\n* Experience working with large\\-scale infrastructure, including cloud data warehousing, distributed computing, and advanced storage solutions.\n* Familiarity with automated data lineage and data auditing tools to streamline data governance and improve transparency.\n* Expertise with BI and visualization tools (e.g., Tableau, Looker) and advanced processing frameworks (e.g., Hive, Presto) for managing high\\-volume data sets and delivering insights across the organization.\n\n  \n\nWhy SPNI?\n\n  \n\nJoin Our Team at SonyLIV \u2013 Drive the Future of Data\\-Driven Entertainment\n\n\nAre you passionate about working with big data? Do you want to shape the direction of products that impact millions of users daily? If so, we want to connect with you. We\u2019re seeking a leader for our Data Engineering team who will collaborate with Product Managers, Data Scientists, Software Engineers, and ML Engineers to support our AI infrastructure roadmap. In this role, you\u2019ll design and implement the data architecture that guides decision\\-making and drives insights, directly impacting our platform\u2019s growth and enriching user experiences.\n\n\nAs a part of SonyLIV, you\u2019ll work with some of the brightest minds in the industry, access one of the most comprehensive data sets in the world and leverage cutting\\-edge technology. Your contributions will have a tangible effect on the products we deliver and the viewers we engage.\n\n\nThe ideal candidate will bring a strong foundation in data infrastructure and data architecture, a proven record of leading and scaling data teams, operational excellence to enhance efficiency and speed, and a visionary approach to how Data Engineering can drive company success. If you\u2019re ready to make a significant impact in the world of OTT and entertainment, let\u2019s talk.",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE7878.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/7878\/sony-pictures-entertainment-squarelogo-1573432718022.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-WrMy7djJS6w7N2bIAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.linkedin.com\/jobs\/view\/data-scientist-ii-alexa-sensitive-content-intelligence-at-amazonodotcom-4164137268?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Data Scientist - II, Alexa Sensitive Content Intelligence",
        "company":"AmazonOdotcom",
        "location":"Bengaluru, Karnataka",
        "date_posted":1740441600000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Alexa is the voice activated digital assistant powering devices like Amazon Echo, Echo Dot, Echo Show, and Fire TV, which are at the forefront of this latest technology wave. To preserve our customers experience and trust, the Alexa Sensitive Content Intelligence (ASCI) team builds services and tools through Machine Learning techniques to implement our policies to detect and mitigate sensitive content in across Alexa.\n\nWe are looking for a passionate, talented, and inventive Data Scientist-II to help build industry-leading technology with Large Language Models (LLMs) and multimodal systems, requiring good learning and generative models knowledge. You will be working with a team of exceptional Data Scientists working in a hybrid, fast-paced organization where scientists, engineers, and product managers work together to build customer-facing experiences. You will collaborate with other data scientists while understanding the role data plays in developing data sets and exemplars that meet customer needs. You will analyze and automate processes for collecting and annotating LLM inputs and outputs to assess data quality and measurement.\n\nYou will apply state-of-the-art Generative AI techniques to analyze how well our data represents human language and run experiments to gauge downstream interactions. You will work collaboratively with other data scientists and applied scientists to design and implement principled strategies for data optimization.\n\nKey Job Responsibilities\n\nA Data Scientist-II should have a reasonably good understanding of NLP models (e.g. LSTM, LLMs, other transformer-based models) or CV models (e.g. CNN, AlexNet, ResNet, GANs, ViT) and know of ways to improve their performance using data. You leverage your technical expertise in improving and extending existing models. Your work will directly impact our customers in the form of products and services that make use of speech, language, and computer vision technologies.\n\nYou will be joining a select group of people making history producing one of the most highly rated products in Amazon's history, so if you are looking for a challenging and innovative role where you can solve important problems while growing in your career, this may be the place for you.\n\nA day in the life\n\nYou will be working with a group of talented scientists on running experiments to test scientific proposal\/solutions to improve our sensitive content detection and mitigation for worldwide coverage. This will involve collaboration with partner teams including engineering, PMs, data annotators, and other scientists to discuss data quality, policy, model development, and solution implementation. You will work with other scientists, collaborating and contributing to extending and improving solutions for the team.\n\nAbout The Team\n\nThe mission of the Alexa Sensitive Content Intelligence (ASCI) team is to (1) minimize negative surprises to customers caused by sensitive content, (2) detect and prevent potential brand-damaging interactions, and (3) build customer trust through appropriate interactions on sensitive topics.\n\nThe term sensitive content includes within its scope a wide range of categories of content such as offensive content (e.g., hate speech, racist speech), profanity, content that is suitable only for certain age groups, politically polarizing content, and religiously polarizing content. The term content refers to any material that is exposed to customers by Alexa (including both 1P and 3P experiences) and includes text, speech, audio, and video.\n\nBasic Qualifications\n\u2022 3 years of data scientist experience\n\u2022 3 years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical\/mathematical software (e.g. R, SAS, Matlab, etc.) experience\n\u2022 3 years of machine learning\/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\n\u2022 Experience applying theoretical models in an applied environment\n\u2022 Experience with big data: processing, filtering, and presenting large quantities (100K to millions of rows) of data\n\nPreferred Qualifications\n\u2022 Experience in Python, Perl, or another scripting language\n\u2022 Experience diving into data to discover hidden patterns and conducting error\/deviation analysis\n\nOur inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit Amazon Accommodations for more information. If the country\/region youre applying in isnt listed, please contact your Recruiting Partner.\n\nLocations - Bengaluru, Karnataka, IND",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-PFofDqx1Wg27ZH7wAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.linkedin.com\/jobs\/view\/cyber-and-data-analytics-audit-assistant-vice-president-at-state-street-4168099556?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Cyber and Data Analytics Audit, Assistant Vice President",
        "company":"State Street",
        "location":"Bengaluru, Karnataka",
        "date_posted":1740441600000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Who We Are Looking For\n\nWe are looking for a highly skilled and experienced Cyber and Data Analytics Auditor, Assistance Vice President to join our global Cyber Audit team. To succeed in this role, you need to have a deep understanding of cyber risks processes, controls, industry standards, and should have a strong knowledge of NIST, MITRE, and Defense in Depth concepts. You will also be responsible for developing and implementing analytics-based services and solutions and to drive efficiencies and systemically broaden the bank\u2019s cyber assurance coverage. You will be responsible for working closely with peers from infrastructure, security, and application audit teams while working within a diverse global team. Collaboration with the bank\u2019s cyber security organization is essential. In this role you will join a growing team that is focused on building leading practices, and you will have a functional reporting line to the Vice President of Cyber Audit. The role will be located in Toronto (Canada), Boston (USA), London (UK), or Bangalore (India)\n\nWhy this role is important to us\n\nThe team you will be joining plays an important role in the overall success of the organization. Across the globe, institutional investors rely on us to help them manage risk, respond to challenges, and drive performance and profitability. To make that happen we need teams like yours to help navigate employees and the organization as a whole. In your role you will strive for cutting-edge solutions, that are straightforward and scalable. You will help us build resilience and execute day to day deliverables at our best. Join us if making your mark in the financial services industry from day one is a challenge you are up for.\n\nWhat You Will Be Responsible For\n\nAs Cyber and Data Analytics Audit, Assistance Vice President, you will\n\u2022 Work as part of an international team, collaborating closely with global peers for infrastructure, security, application, and business audit.\n\u2022 Design, coordinate, and implement data analytic cyber solutions to support audit and innovation initiatives within the planning, assessment, and reporting phases of cyber audits and cyber focused validation activities.\n\u2022 Advise Corporate Audit stakeholders on cyber-related data analytic options to address their specific needs, including discussing potential analytical approaches to problems, associated costs and trade-offs, and recommendations.\n\u2022 Contribute to the timely execution of innovative analytics-based and process automation solution development within cyber audits and cyber focused validation activities to advance insight-driven assurance and visualization of results and quantitative analytics.\n\u2022 Maintain a thorough knowledge of cyber risks, changes in the regulatory environment pertaining to cyber, and innovative assurance approaches.\n\u2022 Develop and maintain relationships with key stakeholders across the organization, including the bank\u2019s cyber security organization.\n\u2022 Communicate audit progress and findings effectively to senior management.\n\u2022 Prepare and review audit work papers to ensure compliance with the division\u2019s audit methodology.\n\nWhat We Value\n\nThese skills will help you succeed in this role\n\u2022 Experience leading and supervising audit projects, preferably within the global financial services industry.\n\u2022 Proficiency in evaluating cyber risks and testing internal controls while applying risk based testing approaches.\n\u2022 Ability to prioritize multiple tasks, working independently and developing relationships with global stakeholders in a fast paced environment.\n\u2022 Excellent analytical, problem solving, communication (written and verbal), interpersonal, organizational, and presentation skills.\n\u2022 Strong communication, interpersonal, and leadership ability across all levels coupled with effective problem solving, conceptual thinking, quantitative and analytical skills.\n\u2022 Strong written and verbal communication, presentation, and technical writing skills.\n\u2022 Advanced project management skills.\n\u2022 Fluency in English - written and spoken.\n\nEducation & Preferred Qualifications\n\u2022 Bachelor's degree in Information Technology, Computer Science or a related field, and statistics, data science, MIS, engineerings, math, accounting, or finance..\n\u2022 5+ years of experience auditing information security, cyber risk management, and experience with data analytics tools such as PC SAS, Enterprise Guide, SQL, Business Objects, Qlikview, Tableau, or Spotfire.\n\u2022 Audit or assurance experience working in the banking or financial services industry or other regulated industries.\n\u2022 Expertise in evaluating cyber security risks and the ability to develop and implement effective audit testing strategies with a strong understanding of regulatory compliance requirements for the banking industry.\n\u2022 Strong knowledge of Cyber and Cloud technologies and tools (Azure, AWS, Snowflake, Databricks, Alteryx), Identity and Access Management, Security Incident and Event Management (SIEM) technologies and cyber operations, and incident and response processes.\n\u2022 Exposure to Big Data Initiatives such as Hadoop, Hive, Cloudera, or large data warehousing initiatives.\n\u2022 Experience with programming and analytic languages such as SAS, R or Python; working experience with large and diverse RDBMS OLTP or OLAP data stores (Oracle, SQL Server, Teradata).\n\u2022 Relevant certifications, such as CISSP, CISA, CISM, CCSP, SAS Certification, ACDA, CAP, CCP, CIA, CFE, CFA, or FRM are highly preferred.\n\nAdditional Requirements\n\u2022 Willingness to travel as required.\n\nAre you the right candidate? Yes!\n\nWe truly believe in the power that comes from the diverse backgrounds and experiences our employees bring with them. Although each vacancy details what we are looking for, we don\u2019t necessarily need you to fulfil all of them when applying. If you like change and innovation, seek to see the bigger picture, make data driven decisions and are a good team player, you could be a great fit.\n\nAbout State Street\n\nWhat we do. State Street is one of the largest custodian banks, asset managers and asset intelligence companies in the world. From technology to product innovation, we\u2019re making our mark on the financial services industry. For more than two centuries, we\u2019ve been helping our clients safeguard and steward the investments of millions of people. We provide investment servicing, data & analytics, investment research & trading and investment management to institutional clients.\n\nWork, Live and Grow. We make all efforts to create a great work environment. Our benefits packages are competitive and comprehensive. Details vary by location, but you may expect generous medical care, insurance and savings plans, among other perks. You\u2019ll have access to flexible Work Programs to help you match your needs. And our wealth of development programs and educational support will help you reach your full potential.\n\nInclusion, Diversity and Social Responsibility. We truly believe our employees\u2019 diverse backgrounds, experiences and perspectives are a powerful contributor to creating an inclusive environment where everyone can thrive and reach their maximum potential while adding value to both our organization and our clients. We warmly welcome candidates of diverse origin, background, ability, age, sexual orientation, gender identity and personality. Another fundamental value at State Street is active engagement with our communities around the world, both as a partner and a leader. You will have tools to help balance your professional and personal life, paid volunteer days, matching gift programs and access to employee networks that help you stay connected to what matters to you.\n\nState Street is an equal opportunity and affirmative action employer.\n\nDiscover more at StateStreet.com\/careers\n\nState Street's Speak Up Line\n\nJob ID: R-749936",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-eMT2ox42NBREv-WYAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/en-in.whatjobs.com\/gfj\/96402445?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Data Scientist (Generative AI)",
        "company":"Tuskira",
        "location":"Kota, Andhra Pradesh",
        "date_posted":1740441600000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"About Tuskira\n\nAt Tuskira.ai, we empower organizations to enhance their security defenses without adding new tools. Our AI-powered platform unifies data from over 150 security tools into a security mesh, automating threat validation, optimizing defenses, and ensuring seamless integration across existing systems. We\u2019re on a mission to make cybersecurity smarter, more effective, and less complex.\n\nJoin us in shaping the future of preemptive defense.\n\nRole Overview:\n\nWe are looking for a highly skilled and motivated Data Scientist with experience in Generative AI to join our growing team in India. In this role, you will contribute to developing and deploying AI-driven models that power Tuskira. You will collaborate with engineers, security experts, and data professionals to create innovative solutions that address real-world cybersecurity challenges.\n\nKey Responsibilities:\n\nAI Model Development: Design, develop, and deploy Generative AI models to simulate attack scenarios, automate threat validation, and enhance security insights. Implement advanced machine learning techniques to improve vulnerability detection and risk prioritization.\n\nData Analysis and Insights: Analyze large-scale structured and unstructured cybersecurity data to identify patterns, trends, and actionable insights. Build robust pipelines to preprocess, clean, and normalize data from diverse security tools.\n\nCollaboration and Integration: Work closely with product, engineering, and security teams to align AI solutions with business goals. Integrate AI models into the Tuskira platform, ensuring seamless interaction with APIs and centralized telemetry.\n\nResearch and Innovation: Stay updated with the latest advancements in Generative AI, machine learning, and cybersecurity. Prototype and test new AI-driven features and contribute to the continuous improvement of Tuskira\u2019s platform.\n\nPerformance Optimization: Monitor, evaluate, and optimize model performance in production environments, ensuring scalability and reliability.\n\nQualifications:\nBachelor\u2019s or Master\u2019s in Computer Science, Data Science, Artificial Intelligence, or a related field. 5+ years of experience in data science or machine learning roles, with hands-on experience in Generative AI. Strong understanding of Generative AI techniques (e.g., GANs, VAEs, transformers). Experience working with large datasets and tools Familiarity with cybersecurity concepts and data (e.g., CVEs, attack paths, threat intelligence) is a plus. Excellent problem-solving skills, a proactive mindset, and the ability to work independently and collaboratively.\n\nPreferred Skills:\nKnowledge of cloud platforms like AWS, Azure, or GCP. Experience with Natural Language Processing (NLP) and language models. Familiarity with cybersecurity tools and frameworks (e.g., SIEM, EDR, CSPM). Strong communication skills to explain technical concepts to non-technical stakeholders.\n\nWhy Join Tuskira?\nBe part of a fast-growing, innovative cybersecurity startup. Work on newly evolving AI technologies and their real-world applications. Collaborate with a global team of industry experts. Competitive salary and benefits package. Opportunities for growth, learning, and making a tangible impact in cybersecurity.\n\nHow to Apply:\n\nIf you\u2019re passionate about using AI to solve complex problems and want to join a team redefining cybersecurity, we\u2019d love to hear from you. Apply now with your resume and a brief statement about your experience with Generative AI.\n\nWe'd love to have you on our team if you thrive on solving complex challenges and delivering technical solutions that drive success. Apply now to join us at Tuskira.ai!",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-2ZWaOAQjuqreqY7PAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/www.shine.com\/jobs\/security-data-scientist\/arctic-wolf\/16606567?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Security Data Scientist",
        "company":"Arctic Wolf",
        "location":"Karnataka",
        "date_posted":1739404800000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Arctic Wolf, with its unicorn valuation, is the leader in security operations in an exciting and fast-growing industrycybersecurity. We have won countless awards for our excellence in security operations and remain dedicated to providing an industry-leading customer and employee experience.\n\nOur mission is simple: End Cyber Risk. Were looking for a Security Data Scientist to be a part of making this happen.\n\nAbout The Role\n\nData is a critical part of Arctic Wolf Networks mission to solve cyber risk, where we process and analyze hundreds of billions of events every day to look for malicious and risky behaviour. Furthermore, were geeks at heart and are passionate about data and solving cybersecurity problems for our customers. The AI & Data Science team works on analyzing Arctic Wolfs product platforms, internal business challenges, and customer pain points to develop new products and features for our customers.\n\nAs a Security Data Scientist on the AI & Data Science team you will be responsible for developing data-driven solutions leveraging cutting-edge advanced analytics techniques. This involves working closely with engineering, product, operations, and other teams to understand the most important technical and business analytics needs to drive security-centric analytics outcomes. A successful candidate is self-motivated with a passion for excellence and attention to detail.\n\nAs a Security Data Scientist at Arctic Wolf, you will\nAnalyze and correlate complex data from multiple sources.\nPerform exploratory data analysis to gain deeper understanding of the data.\nWork with stakeholders, including domain experts and product, to understand use cases and domain-specific problems and identify opportunities for applying machine learning to drive outcomes.\nDevelop tools and algorithms for generating synthetic data sets.\nDefine KPIs to measure model performance.\nDevelop and test statistical and machine learning models for efficacy and operational impact.\nWrite production quality code and work with other software engineering teams to deploy models into production.\nSupport deployed models as a subject matter expert.\nBe creative and engineer novel features and methods to push beyond our current capabilities.\n\nWe Are Looking For Someone Who Has\nProven track record of a minimum 2+ years of hands-on experiencein the research, data science and engineering around building and shipping machine learning or statistical models that scale to high volumes of data (billions of data points).\nProficiency with Python and SQL.\nExperience using key ML libraries including scikit-learn, tensorflow, pytorch, sparkml.\nExperience with data fusion and data cleansing techniques for creating labelled data sets.\nExperience with developing synthetic data sets using generative and statistical modelling techniques.\nUnderstanding of classical ML and DNN modelling techniques for supervised and unsupervised learning and sequence modelling.\nUnderstanding of 3 of either PGMs, RL, GNN, statistical modelling, or time series modelling.\nUnderstanding of ensembles and multi modal machine learning techniques to solve complex problems.\nFamiliarity of large-scale distributed systems and related technologies such as Spark, Elasticsearch, Kubernetes, etc. is a plus.\nFamiliarity with cloud platforms (we use AWS here) and automation technologies (e.g., Kubernetes, Jenkins, Chef, etc.) is a plus.\nFamiliarity with the information\/cyber security domain is a plus.\n\nAbout Arctic Wolf\n\nAt Arctic Wolf were cultivating a collaborative and productive work environment that welcomes a diversity of backgrounds, cultures, and ideas to make our teams even stronger as we grow globally. Weve been named one of the 50 Most Innovative Companies in the world for 2022 (Fast Company)and the 2nd Most Innovative Security Company. We have won countless awards for our excellence in security operations and remain dedicated to providing an industry-leading customer and employee experience including:\nTop Workday USA (2021-2024)\nGreat Place to Work (2022-2024) & Best Workplaces for Women (2024) in Canada\nBest Workplaces in Tech & For Women in the UK (2023)\nTop Company by Kununu in Germany (2024)\n\nOur Values\n\nArctic Wolf recognizes that success comes from delighting our customers, so we work together to ensure that happens every day. We believe in diversity and inclusion, and truly value the unique qualities and unique perspectives all employees bring to the organization. And we appreciate thatby protecting peoples and organizations sensitive data and seeking to end cyber risk we get to work in an industry that is fundamental to the greater good.\n\nWe celebrate unique perspectives by creating a platform for all voices to be heard through our Pack Unity program. We encourage all employees to join or create a new alliance. See more about our Pack Unity here.\n\nSecurity Requirements\nConducts duties and responsibilities in accordance with AWNs Information Security policies, standards, processes, and controls to protect the confidentiality, integrity and availability of AWN business information (in accordance with our employee handbook and corporate policies).\nBackground checks are required for this position.,",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-36HbPc-byxa3XtNXAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.indeed.com\/viewjob?jk=0ae210a2258aee02&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"I&F-Cyber Security-Investigations & Forensics-Data Analytics -Senior Associate \u2013 Bangalore",
        "company":"PwC",
        "location":"Karnataka",
        "date_posted":1738627200000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Line of Service\nAdvisory\n\nIndustry\/Sector\nNot Applicable\n\nSpecialism\nFraud, Investigations & Regulatory Enforcement (FIRE)\n\nManagement Level\nSenior Associate\n\nJob Description & Summary\nA career in our Cybersecurity, Privacy and Forensics will provide you the opportunity to solve our clients most critical business and data protection related challenges. You will be part of a growing team driving strategic programs, data analytics, innovation, deals, cyber resilency, response, and technical implementation activities. You will have access to not only the top Cybersecurity, Privacy and Forensics professionals at PwC, but at our clients and industry analysts across the globe.\n\nOur Investigations team focuses on helping our clients to detect and investigate fraudulent activities or irregularities within their organisation. As part of our team, you will perform fraud investigations, forensic accounting engagements, litigation support, crisis response, insurance claims support, and address anti-kickback and anti-bribery matters for a diverse group of both public and private multinational clients, not-for profits and state and local governments. You will work closely with the office of general counsel, chief compliance officers, boards and outside counsel. Our team not only helps clients respond to instances of fraud or irregularity, but also works with them to emerge stronger as an entity.\n\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades\/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\n\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\n\u2022 Use feedback and reflection to develop self awareness, personal strengths and address development areas.\n\u2022 Delegate to others to provide stretch opportunities and coach to help deliver results.\n\u2022 Develop new ideas and propose innovative solutions to problems.\n\u2022 Use a broad range of tools and techniques to extract insights from from current trends in business area.\n\u2022 Review your work and that of others for quality, accuracy and relevance.\n\u2022 Share relevant thought leadership.\n\u2022 Use straightforward communication, in a structured way, when influencing others.\n\u2022 Able to read situations and modify behavior to build quality, diverse relationships.\n\u2022 Uphold the firm's code of ethics and business conduct.\n\nOverview:\nPwC\u2019s Insights & Forensics (I&F) Data Analytics team in the Acceleration Center (AC) is seeking a highly skilled and motivated Senior Associate to join our dynamic team. The ideal candidate will bring technical expertise, innovative thinking, and strong analytical skills to deliver insights and value to our clients. This role demands a hands-on professional who can seamlessly work with cross-functional teams, process large volumes of data, and create impactful visualizations and analytics solutions.\n\nKey Responsibilities:\n\u2022 Data Analysis & Visualization:\n\u2022 Develop and design interactive dashboards, reports, and data visualizations using Power BI and Tableau to provide actionable insights.\n\u2022 Collaborate with stakeholders to gather business requirements and transform them into meaningful visuals and stories.\n\u2022 Data Engineering & Analytics Development:\n\u2022 Utilize Python and PySpark to process, transform, and analyze large datasets efficiently.\n\u2022 Implement advanced SQL queries and Alteryx for complex data manipulation, reporting, and validation.\n\u2022 Cloud Analytics Solutions:\n\u2022 Build, maintain, and optimize analytics workflows using Azure Synapse Analytics and Databricks .\n\u2022 Leverage cloud-based solutions to design scalable data pipelines and integrate disparate data sources.\n\u2022 Collaboration & Delivery:\n\u2022 Partner with US stakeholders and internal teams to understand key business problems and deliver analytics-driven solutions.\n\u2022 Document technical workflows, processes, and best practices to ensure high-quality deliverables and knowledge sharing.\n\nRequired Skills & Qualifications:\n\u2022 Technical Proficiency:\n\u2022 Expert-level knowledge and hands-on experience with Power BI for data visualization and reporting.\n\u2022 Proficient in programming with Python and working with distributed computing frameworks like PySpark .\n\u2022 Strong command of Advanced SQL and Alteryx for data analysis and manipulation across relational databases.\n\u2022 Demonstrated expertise in working with Azure Synapse Analytics and Databricks for building cloud-based data solutions.\n\u2022 Problem-Solving & Analytical Thinking:\n\u2022 Strong ability to analyze complex business problems and translate them into data-driven solutions.\n\u2022 Creative mindset with a focus on delivering value through innovative approaches to analytics and visualization.\n\u2022 Communication & Collaboration:\n\u2022 Excellent verbal and written communication skills for engaging with stakeholders and explaining technical concepts.\n\u2022 Ability to work independently and collaboratively within a team, ensuring high standards of delivery.\n\u2022 Education & Experience:\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Data Analytics, Information Systems, or a related field.\n\u2022 5-7 years of relevant experience in data analytics, data engineering, or business intelligence roles.\n\u2022 Experience in professional services or consulting is a plus.\n\nGood to Have Skills:\n\u2022 Experience in Prompt Engineering and working with Generative AI (GenAI) solutions.\n\u2022 Knowledge of Data Science concepts and methodologies.\n\u2022 Familiarity with Machine Learning techniques and frameworks.\n\u2022 Education & Experience:\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Data Analytics, Information Systems, or a related field.\n\u2022 5-7 years of relevant experience in data analytics, data engineering, or business intelligence roles.\n\u2022 Experience in professional services or consulting is a plus.\n\nEducation (if blank, degree and\/or field of study not specified)\nDegrees\/Field of Study required:\n\nDegrees\/Field of Study preferred:\n\nCertifications (if blank, certifications not specified)\n\nRequired Skills\n\nOptional Skills\nAccepting Feedback, Accepting Feedback, Active Listening, Analytical Thinking, Communication, Compliance Oversight, Compliance Risk Assessment, Corporate Governance, Creativity, Cybersecurity, Data Analytics, Debt Restructuring, Embracing Change, Emotional Regulation, Empathy, Evidence Gathering, Financial Crime Compliance, Financial Crime Investigation, Financial Crime Prevention, Financial Record Keeping, Financial Transactions, Forensic Accounting, Forensic Investigation, Fraud Detection, Fraud Investigation {+ 12 more}\n\nDesired Languages (If blank, desired languages not specified)\n\nTravel Requirements\nNot Specified\n\nAvailable for Work Visa Sponsorship?\nNo\n\nGovernment Clearance Required?\nNo",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-AWk_RNH2T0hHGR0eAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.indeed.com\/viewjob?jk=e2681ad498a13fa2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"CyberSecurity Data Scientist, Account and Device Intelligence",
        "company":"Google",
        "location":"Karnataka",
        "date_posted":null,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Minimum qualifications:\n\u2022 Bachelor's degree or equivalent practical experience.\n\u2022 2 years of experience in data analysis, including identifying trends, generating summary statistics, and drawing insights from quantitative and qualitative data.\n\u2022 2 years of experience managing projects and defining project scope, goals, and deliverables.\n\nPreferred qualifications:\n\u2022 Master's degree or PhD in Computer Science, Engineering, Mathematics, Physics or a related technical field.\n\u2022 Experience in large-scale data analysis and related tools and processes.\n\u2022 Experience in automating processes or applied AI.\n\u2022 Knowledge in account security, network engineering, malware or artificial intelligence.\n\nAbout the job\n\nIn this role, you will be working with a team of analysts that assess and address threats against Google accounts. You will identify and solve complex issues at scale and have investigative and technical skills. You will be proactive, motivated, organized, responsible, innovative and are able to work well in a fluid, global, cross-functional, and team-oriented environment and demonstrate technical know-how, effective communication to get things done. You will also work very closely with engineering teams and product teams to make sure that new products and features provide a good, safe experience for users. You will build, leverage and evaluate ML\/AI models to solve cybersecurity and abuse issues.\nAt Google we work hard to earn our users\u2019 trust every day. Trust Safety is Google\u2019s team of abuse fighting and user trust experts working daily to make the internet a safer place. We partner with teams across Google to deliver bold solutions in abuse areas such as malware, spam and account hijacking. A diverse team of Analysts, Policy Specialists, Engineers, and Program Managers, we work to reduce risk and fight abuse across all of Google\u2019s products, protecting our users, advertisers, and publishers across the globe in over 40 languages.\n\nResponsibilities\n\u2022 Provide high-quality, detailed and actionable qualitative and quantitative understanding of the threat landscape, designing and improving additional data collection, processes and quality measures.\n\u2022 Design and build early warning alerts for novel and changing account threats, based on researching, understanding and experimenting with attacker operations and attacker interactions with our systems.\n\u2022 Provide and apply our threat intelligence to be ready to respond to new adversarial campaigns.\n\u2022 Lead incident response to incidents efforts for Google, including the special response in case of severe incidents in collaboration with the UP\/Account and Device Intelligence (ADI) team.\n\u2022 Work together with our GOC team (located in Hyderabad) to scale the operational work required to protect Google accounts, such as handling low severity escalations and alerts, and maintaining the ground truth quality. Provide the training and work with UP\/ADI.\n\nGoogle is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See alsoGoogle's EEO Policy andEEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing ourAccommodations for Applicants form.",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4094667451",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4094667451",
        "job_url_direct":"https:\/\/jobs.exxonmobil.com\/ExxonMobil\/job\/Bengaluru-Commercial-Data-Scientist-KA\/1240201900\/?feedId=223600&utm_source=LinkedInJobPostings&utm_campaign=EOM_Linkedin&urlHash=YnMb",
        "title":"Commercial Data Scientist",
        "company":"ExxonMobil",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":1740528000000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"entry level",
        "job_function":"Engineering and Information Technology",
        "listing_type":null,
        "emails":null,
        "description":"**About Us**\n At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net\\-zero future. As one of the world\u2019s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.\n   \n\n  \n\n The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower\\-emissions technologies.\n   \n\n  \n\n We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society\u2019s evolving needs. Learn more about\n **our What and our Why** \n and how we can work\n **together** \n .\n   \n\n  \n\n**What Role You Will Play In Our Team**\n We are seeking candidates to tackle challenging commercial problems in pricing, marketing, sales, transportation, storage, and distribution of hydrocarbons. The ideal candidate will understand both the commercial\/economic and technical aspects of the oil and gas sector and will be able to formulate and solve oil and gas industry problems using data science, econometrics, statistical analysis, and programming skills.\n   \n\n  \n\n**What You Will Do**\n* Collaborate with data scientists, data analysts, software developers, business representatives from chemical, lubricants, and fuels value chains, and demand planners globally to develop, deliver, and apply computational tools, models, or software to support our business.\n* Utilize machine learning, time series analysis, pattern recognition, statistical analysis, design of experiments, and data visualizations, along with domain knowledge, to solve commercial and logistics problems and provide business insights.\n* Design, build, and execute studies using proprietary or commercial tools to provide insights, including calibrating models to pricing\/sales\/demand data and providing optimized recommendations.\n\n\n**About You**\n**Skills and Qualifications**\n* Bachelor\u2019s, Master\u2019s, or PhD degree from a recognized university in Data Science, Computer Science, IT, Applied Mathematics, Statistics, Engineering, or related disciplines with a minimum GPA of 7\\.0 (out of 10\\.0\\).\n* At least 2 years of experience in developing, applying, and validating data\\-driven tools to model complex systems.\n* In\\-depth knowledge and practical experience in statistical analysis techniques (e.g., classification, regression, time\\-series, Bayesian techniques) and machine learning techniques (e.g., decision trees, ensemble methods, deep learning, neural networks, validation methods).\n* Practical experience in the full machine learning lifecycle, from problem formulation and data acquisition to model building and deployment at enterprise scale.\n* Specialization in at least one sub\\-domain, such as time series forecasting, econometrics, statistics, or NLP.\n* Proficiency in Python and R, including packages such as NumPy, pandas, scikit\\-learn, Keras, TensorFlow, and PyTorch.\n* Experience with software engineering practices, agile methodologies, DevOps, and version control.\n* Experience working with Azure Databricks or other data science frameworks.\n* Familiarity with software testing and development practices (Agile).\n* Experience with data visualization tools (e.g., Tableau, Power BI).\n\n\n**Preferred Qualifications \/ Experience**\n* Knowledge of supply chain operations, including demand planning, inventory optimization, vehicle routing, and network optimization.\n* Prior experience in commercial software development or working in commercial software teams.\n* Ability to identify and scope data science opportunities based on business needs.\n* Strong communication and interpersonal skills, with the ability to work collaboratively in a global team environment.\n* Excellent problem\\-solving skills and attention to detail.\n\n\n**Your Benefits**\n An ExxonMobil career is one designed to last. Our commitment to you runs deep our employees grow personally and professionally, with benefits built on our core categories of health, security, finance and life. We offer you:\n   \n\n  \n\n* Competitive compensation\n* Medical plans, maternity leave and benefits, life, accidental death and dismemberment benefits\n* Retirement benefits\n* Global networking \\& cross\\-functional opportunities\n* Annual vacations \\& holidays\n* Day care assistance program\n* Training and development program\n* Tuition assistance program\n* Workplace flexibility policy\n* Relocation program\n* Transportation facility\n\n\n Please note benefits may change from time to time without notice, subject to applicable laws. The benefits programs are based on the Company\u2019s eligibility guidelines.\n   \n\n  \n\n**Stay connected with us**\n* Learn more about ExxonMobil in India, visit ExxonMobil India and Energy Factor India.\n* Follow us on LinkedIn and ExxonMobil (@exxonmobil)\n * Instagram photos and videos\n* Like us on Facebook\n* Subscribe our channel at YouTube\n**EEO Statement**\n ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin or disability status.\n   \n\n  \n\n**Business solicitation and recruiting scams**\n ExxonMobil does not use recruiting or placement agencies that charge candidates an advance fee of any kind (e.g., placement fees, immigration processing fees, etc.). Follow the LINK to understand more about recruitment scams in the name of ExxonMobil.\n   \n\n  \n\n Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship.\n   \n\n  \n\n Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co\\-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.",
        "company_industry":"Oil and Gas",
        "company_url":"https:\/\/www.linkedin.com\/company\/exxonmobil",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C4D0BAQE_IRWZ2qVHpw\/company-logo_100_100\/company-logo_100_100\/0\/1631303598129?e=2147483647&v=beta&t=20NshSkLIzCoKGk7fkNxWckGM7OnZQ5_ddDzZ5Pcwqk",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4102465940",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4102465940",
        "job_url_direct":"https:\/\/careers.mcafee.com\/global\/en\/job\/MCAFGLOBALJR0031560ENGLOBALEXTERNAL\/ML-Platform-Engineer-Remote?utm_source=linkedin&utm_medium=phenom-feeds&source=LinkedIn&urlHash=-fEN",
        "title":"ML Platform Engineer - Remote",
        "company":"McAfee",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":1740528000000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"not applicable",
        "job_function":"Engineering and Information Technology",
        "listing_type":null,
        "emails":null,
        "description":"**Role Overview**\n As a Cloud and Platform engineer within the Office of the CTO working on the AI Automation team at McAfee, you will play a vital role in providing our customers with cutting edge protection and peace of mind.\n   \n\n  \n\n You will leverage McAfee\u2019s rich data ecosystems to create pipelines that will continuously retrain, validate and approve ML models to deliver incremental value in pursuit of providing the best protection in cybersecurity. You\u2019ll have the opportunity to work with big data to identify potential improvements in our threat protection capabilities. You\u2019ll have the ability to improve our ML and AI automation platform to automate the end\\-to\\-end model development and deployment lifecycle. You\u2019ll work closely with Data Scientists to set up model automation workflows to enable high frequency retraining and deployment.\n   \n\n  \n\n This is a remote position in India. We will only consider candidates currently in India and are not offering relocation assistance at this time.\n   \n\n  \n\n**About The Role**\n* Develop and maintain scalable pipelines for ML model retraining, containerization, validation and approval.\n* Develop and maintain model training datasets.\n* Collaborate with Data Scientists to design, validate, deploy, monitor and maintain production scale ML models.\n* Build and maintain solutions on Databricks, AWS, EKS and Kubeflow.\n* Scale up existing pipelines to work with larger datasets and optimize resource usage.\n* Build and maintain infrastructure as code (IaC) in the cloud, that is resilient and can scale when needed.\n* Work with stakeholders across the organization to identify opportunities utilizing big data from many different sources.\n\n\n**About You**\n* 6\\-8 years of experience as a software engineer, with expertise in building ML and data pipelines (cybersecurity experience is a plus).\n* Bachelor\u2019s degree in IT, Software Engineering, or Computer Science is preferred.\n* Proficient in Python, Linux shell scripting, and tools like PySpark, Pandas, and NumPy.\n* Hands\\-on experience with Databricks, big data management, and core AWS services (EC2, S3, CloudWatch, Lambda, etc.).\n* Knowledge of containerization (Kubernetes\/EKS) and infrastructure\\-as\\-code tools (Terraform or CloudFormation).\n* Skilled in debugging computational bottlenecks, troubleshooting, software testing, and optimizing data pipelines.\n* Self\\-motivated, strong problem\\-solving skills, and comfortable collaborating remotely with international teams.\n\n\n**Company Overview**\n McAfee is a leader in personal security for consumers. Focused on protecting people, not just devices, McAfee consumer solutions adapt to users\u2019 needs in an always online world, empowering them to live securely through integrated, intuitive solutions that protects their families and communities with the right security at the right moment.\n   \n\n  \n\n**Company Benefits And Perks**\n We work hard to embrace diversity and inclusion and encourage everyone at McAfee to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family\\-friendly benefits to all of our employees.\n   \n\n  \n\n* Bonus Program\n* Pension and Retirement Plans\n* Medical, Dental and Vision Coverage\n* Paid Time Off\n* Paid Parental Leave\n* Support for Community Involvement\n\n\n We're serious about our commitment to diversity which is why McAfee prohibits discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.",
        "company_industry":"Computer and Network Security",
        "company_url":"https:\/\/www.linkedin.com\/company\/mcafee",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/D4E0BAQF8epKyYz-LlQ\/company-logo_100_100\/company-logo_100_100\/0\/1719941820047\/mcafee_logo?e=2147483647&v=beta&t=Sb0C_tEZLIui7CdXXS0WI_g39zq2__jobRy6uzMpEUI",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4164793176",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4164793176",
        "job_url_direct":null,
        "title":"Sr Machine Learning Engineer",
        "company":"Target",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":1740441600000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"associate",
        "job_function":"Engineering",
        "listing_type":null,
        "emails":null,
        "description":"**About us:** \n\n\n\n\n  \n\n\n\n\n\n As a Fortune 50 company with more than 400,000 team members worldwide, Target is an iconic brand and one of America's leading retailers. Joining Target means promoting a culture of mutual care and respect and striving to make the most meaningful and positive impact. Becoming a Target team member means joining a community that values diverse voices and lifts each other up. Here, we believe your unique perspective is important, and you'll build relationships by being authentic and respectful.\n \n\n\n\n  \n\n\n\n\n\n**Overview about Target In India** \n\n\n\n\n  \n\n\n\n\n\n At Target, we have a timeless purpose and a proven strategy. And that hasn\u2019t happened by accident. Some of the best minds from diverse backgrounds come together at Target to redefine retail in an inclusive learning environment that values people and delivers world\\-class outcomes. That winning formula is especially apparent in Bengaluru, where Target in India operates as a fully integrated part of Target\u2019s global team and has more than 4,000 team members supporting the company\u2019s global strategy and operations.\n \n\n\n\n  \n\n\n\n\n\n**Pyramid overview** \n\n\n\n\n  \n\n\n\n\n\n A role with Target Data Science \\& Engineering means the chance to help develop and manage state of the art predictive algorithms that use data at scale to automate and optimize decisions at scale. Whether you join our Statistics, Optimization or Machine Learning teams, you\u2019ll be challenged to harness Target\u2019s impressive data breadth to build the algorithms that power solutions our partners in in Marketing, Supply Chain Optimization, Network Security and Personalization rely on\n \n\n\n\n  \n\n\n\n\n\n**About The role** \n\n\n\n\n  \n\n\n\n\n\n As Senior Engineer, you will join a Target Tech team responsible for Promotion forecasting and optimization. You will play crucial role in designing, implementing, and optimizing the machine learning solutions in production. Additionally, you\u2019ll apply best practices in software design, participate in code reviews, create a maintainable well\\-tested codebase with relevant documentation. At an organizational level, you will conduct training sessions, present work to technical and non\\-technical peers\/leaders, build knowledge on business priorities\/strategic goals and leverage this knowledge while building requirements and solutions for each business need. Core responsibilities of this job are articulated within this job description. Job duties may change at any time due to business needs.\n \n\n\n\n  \n\n\n\n\n\n**About you:** \n\n\n\n\n  \n\n\n\n\n* 4\\-year degree in Quantitative disciplines (Science, Technology, Engineering, Mathematics) or equivalent experience\n* MS in Computer Science, Applied Mathematics, Statistics, Physics or equivalent work or industry experience\n* 4 plus years of experience in end\\-to\\-end application development, data exploration, data pipelining, API design, optimization of model latency\n* Expertise in MLOps frameworks and hands on experience in MLOps tools preferably Google Vertex ai\n* 2 plus years of experience deploying Machine Learning algorithms into production environments \\- including model and system monitoring and troubleshooting\n* Highly proficient programming in Scala and\/ or Python\/Pyspark\n* Good understanding of Big Data tech \\- specifically Hadoop, Kafka, Spark\n* Experience in handling streaming data and real\\-time forecasting solutions deployment\n* Solid understanding of data analysis techniques, including data cleaning, preprocessing, and visualization\n* Demonstrated ability collaborating with data scientists, software engineers and product managers to understand the business requirements and translate to machine learning solutions at scale\n* Excellent communication skills with the ability to clearly tell data driven stories through appropriate visualizations, graphs, and narratives Self\\-driven and results oriented \\- able to meet tight timelines\n* Motivated, team player with ability to collaborate effectively across global team\n* Understanding of retail industry and pricing concepts is added advantage\n\n\n\n  \n\n\n\n\n\n**Bonus Points:** \n\n\n\n\n  \n\n\n\n\n* Extensive experience with Deep Learning frameworks TensorFlow, Pytorch or Keras\n* PhD in Computer Science, Applied Mathematics, Statistics, Physics or related quantitative field\n* Extensive experience developing highly distributed ML systems at scale\n* Familiarity with Vertex AI and Cloud ML ecosystem will be desirable\n* Experience in mentoring the junior team members ML skillset and career development\n\n\n\n  \n\n\n\n\n\n**Useful Links\\-** \n\n\n\n\n  \n\n\n\n\n\n**Life at Target\\- https:\/\/india.target.com\/** \n\n\n\n\n**Benefits\\- https:\/\/india.target.com\/life\\-at\\-target\/workplace\/benefits**",
        "company_industry":"Technology, Information and Media",
        "company_url":"https:\/\/www.linkedin.com\/company\/target",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C4E0BAQGUjozudTh0yg\/company-logo_100_100\/company-logo_100_100\/0\/1631307593526?e=2147483647&v=beta&t=HimTJZJ3k5TBZ_V51SHC25oSIT_mmLNQvAoldmJL9wI",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4166756568",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4166756568",
        "job_url_direct":"https:\/\/www.expertia.ai\/netsach-co-in\/job\/hiring-machine-learning-engineer-66a7ad7831038b43cad1952d?utm_source=linkedin-feed&easy_apply=true&date-refresh=02\/27\/2025&urlHash=sdK8",
        "title":"Machine Learning Engineer",
        "company":"NETSACH GLOBAL",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":null,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"mid-senior level",
        "job_function":"Information Technology",
        "listing_type":null,
        "emails":"emily@netsach.co.in, emily@netsach.co.in",
        "description":"**Skills:**\n Python, Machine Learning Algorithms, Deep Learning, Data Preprocessing, Model Evaluation, Natural Language Processing, Computer Vision TensoFlow, big data technologies,\n   \n\n  \n\n Greeting from Netsach \\- A Cyber Security Company.\n   \n\n  \n\n**Job Summary:** \n We are seeking a talented and innovative Machine Learning Engineer to join our team. The ideal candidate will be responsible for designing, developing, and deploying machine learning models and algorithms to solve complex problems and drive business value. This role requires a strong foundation in machine learning, data science, and software engineering, along with the ability to collaborate with cross\\-functional teams.\n   \n\n  \n\n**Job Title:** \n Machine Learning Engineer\n   \n\n  \n\n**Location:** \n Bangalore (Onsite)\n   \n\n  \n\n**Exp:** \n 2 \\- 8yrs\n   \n\n  \n\n**Job Type:** \n Contract 1\\+yrs Extendable\n   \n\n  \n\n Interested candidates please share your updated resume at emily@netsach.co.in\n   \n\n  \n\n**Key Responsibilities**\n* Design and implement machine learning models and algorithms.\n* Collaborate with data scientists, software engineers, and other stakeholders to understand business requirements and translate them into technical solutions.\n* Preprocess and analyze large datasets to extract meaningful insights.\n* Train, test, and validate machine learning models.\n* Deploy machine learning models into production environments.\n* Monitor and maintain the performance of deployed models.\n* Continuously improve models by incorporating feedback and new data.\n* Stay up\\-to\\-date with the latest advancements in machine learning and artificial intelligence.\n* Develop and maintain documentation for machine learning processes and models.\n* Participate in code reviews and ensure adherence to best practices and coding standards.\n* Provide technical support and guidance to junior team members.\n\n\n**Qualifications**\n* Bachelors or Masters degree in Computer Science, Data Science, Mathematics, or a related field.\n* 3\\+ years of experience in machine learning, data science, or a related role.\n* Strong proficiency in programming languages such as Python, R, or Java.\n* Experience with machine learning frameworks and libraries such as TensorFlow, PyTorch, scikit\\-learn, etc.\n* Solid understanding of data preprocessing, feature engineering, and model evaluation techniques.\n* Experience with big data technologies and distributed computing frameworks (e.g., Hadoop, Spark) is a plus.\n* Strong problem\\-solving and analytical skills.\n* Excellent communication and collaboration abilities.\n* Familiarity with cloud platforms (AWS, Azure, Google Cloud) is desirable.\n* Experience with version control systems, preferably Git.\n* Knowledge of software engineering best practices, including code reviews, testing, and continuous integration.\n\n\n Thank You\n   \n\n  \n\n Emily Jha\n   \n\n  \n\n emily@netsach.co.in\n   \n\n  \n\n Netsach \\- A Cyber Security Company\n   \n\n  \n\n www.netsach.co.in",
        "company_industry":"IT Services and IT Consulting",
        "company_url":"https:\/\/in.linkedin.com\/company\/netsach-global",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C560BAQFmFhT4xMpYxg\/company-logo_100_100\/company-logo_100_100\/0\/1631316502757?e=2147483647&v=beta&t=iR4o5qWoZLcy6FB-q-m6ePtcej4uYr0MpM9nNGycRSI",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4168688621",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4168688621",
        "job_url_direct":"https:\/\/www.hirist.tech\/j\/date-scientist-artificial-intelligencemachine-learning-1440541.html?utm_source=LinkedIn&utm_medium=referral&utm_campaign=linkedin_apply&ref=linkedin&urlHash=MiFF",
        "title":"Date Scientist - Artificial Intelligence\/Machine Learning",
        "company":"Starmark Software",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":null,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"mid-senior level",
        "job_function":"Information Technology",
        "listing_type":null,
        "emails":null,
        "description":"**Job Description**\n Role : AI Engineer \/ Data Scientist\n   \n\n  \n\n**Role Overview**\n We are seeking an accomplished and visionary Data Scientist with minimum 5 Years of experience in Data Science and Machine learning, preferable experience around NLP, Generative AI, LLMs, MLOps, Optimization techniques and AI solution Architecture to lead our AI team and drive the strategic direction of AI initiatives. In this role you will play a key role in the development and implementation of AI solutions, leveraging your technical expertise and leadership skills.\n   \n\n  \n\n The ideal candidate should have a proven track record in AI leadership, a deep understanding of AI technologies, and experience in designing and implementing cutting\\-edge AI models and systems.\n   \n\n  \n\n Additionally, expertise in data engineering, DevOps, and MLOps practices will be valuable in this role. Minimum 5 Years of experience in Data Science and Machine learning. Excellent leadership skills with at least 2\\-3 years of people management OR technical architecture experience.\n   \n\n  \n\n**Responsibilities**\n Your technical responsibilities :\n   \n\n  \n\n* Provide strategic direction and technical leadership for AI initiatives, guiding the team in designing and implementing state\\-of\\-the\\-art AI solutions.\n* Lead the design and architecture of complex AI systems, ensuring scalability, reliability, and performance.\n* Drive the development and implementation of AI models and systems, leveraging techniques such as Language Models (LLMs) and generative AI.\n* Collaborate with stakeholders to identify business opportunities, define AI project goals, and prioritize initiatives based on strategic objectives.\n* Stay updated with the latest advancements in generative AI techniques, such as LLMs, and evaluate their potential applications in solving enterprise challenges.\n* Utilize generative AI techniques, such as LLMs, to develop innovative solutions for enterprise industry use cases.\n* Implement and optimize end\\-to\\-end pipelines for generative AI projects, ensuring seamless data processing and model deployment.\n* Implement similarity search algorithms and techniques to enable efficient and accurate retrieval of relevant information from generative AI outputs.\n* Collaborate with domain experts, stakeholders, and clients to understand specific business requirements and tailor generative AI solutions accordingly.\n* Conduct research and evaluation of advanced AI techniques, including transfer learning, domain adaptation, and model compression, to enhance performance and efficiency.\n* Establish evaluation metrics and methodologies to assess the quality, coherence, and relevance of generative AI outputs for enterprise industry use cases.\n* Ensure compliance with data privacy, security, and ethical considerations in AI applications.\n* Leverage data engineering skills to curate, clean, and preprocess large\\-scale datasets for generative AI applications.\n\n\n**Good To Have Skills**\n* Apply trusted AI practices to ensure fairness, transparency, and accountability in AI models and systems.\n* Experience on Optimization tools and techniques(MIP etc).\n* Drive DevOps and MLOps practices, including continuous integration, deployment, and monitoring of AI models.\n* Implement CI\/CD pipelines and automate model deployment and scaling processes.\n* Utilize tools such as Docker, Kubernetes, and Git for building and managing AI pipelines.\n* Implement monitoring and logging tools to ensure the performance and reliability of deployed AI models.\n* Collaborate with software engineering and operations teams to ensure seamless integration and deployment of AI models.\n\n\n**Your Client Responsibilities**\n* Work for managing the successful design, execution, and measurement of data initiatives across customer\\-facing engagements\n* Communicate with internal stakeholders to make recommendations based on data\n* Sort out business problems to translate into analytical questions to simplify and accelerate the solution development.\n* Balancing excellent business communication skills with a deep analytical understanding is needed\n* Run Scrum calls for team.\n* Manage client delivery.\n* Applying data Science, ML algorithms, using standard statistical tools and techniques for solving client business problems.\n* Regular status reporting to Management\n* Willing to be flexible to work on various tools and technologies based on demand\n\n\n (ref:hirist.tech)",
        "company_industry":"Data Infrastructure and Analytics, Technology, Information and Internet, and Software Development",
        "company_url":"https:\/\/in.linkedin.com\/company\/starmark-services-pvt--ltd-",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C4E0BAQGWfv6-XJkGSQ\/company-logo_100_100\/company-logo_100_100\/0\/1631347775245?e=2147483647&v=beta&t=CN-Zy2X9bZx057odIFKINHlfAGMY4RzhPH1C3MHHots",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    }
]