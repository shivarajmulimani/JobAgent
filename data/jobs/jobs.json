[
    {
        "id":"gd-1009647589791",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009647589791",
        "job_url_direct":null,
        "title":"Data Engineer\/Senior Data Engineer - BLR",
        "company":"Aarki",
        "location":"Bengaluru",
        "date_posted":1740182400000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":485000.0,
        "max_amount":737500.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"**About Us**\n\n\nAarki is an AI company that builds advertising solutions to drive mobile revenue growth. We use AI to find audiences in a privacy\\-first world by using trillions of contextual bidding signals coupled with proprietary behavioral models. Our audience engagement platform includes a full\\-service agency team and Unified Creative Strategy that delivers ad creative ideation and execution. We have worked with hundreds of advertisers over 14 years and see 5M mobile ad requests per second from over 10B devices driving performance for publishers and brands. It is independently operated and headquartered in San Francisco, CA with offices across the United States, EMEA, and APAC.\n\n\n**Role Overview:**  \n\nAarki is seeking a talented **Data Engineer** to join our engineering team. This role is ideal for a skilled developer with a strong background in big data processing, data pipeline development, and distributed systems. As a Data Engineer, you will play a crucial role in designing, building, and maintaining the data infrastructure that powers Aarki's AI\\-driven advertising platform. You will collaborate closely with data scientists, software engineers, and product managers to ensure efficient and scalable data solutions.\n\n\n**Key Responsibilities:**\n\n\n* Design, develop, and maintain scalable data pipelines and ETL processes for handling large\\-scale data from multiple sources.\n* Optimize data storage, processing, and retrieval for high\\-performance analytics and machine learning applications.\n* Work closely with data scientists to prepare, clean, and structure data for machine learning model development and deployment.\n* Develop and maintain real\\-time and batch data processing systems using technologies like Spark, Kafka, and Flink.\n* Implement monitoring, logging, and alerting solutions to ensure the reliability of data pipelines.\n* Ensure data security, governance, and compliance with industry regulations.\n* Collaborate with engineering teams to integrate data solutions into Aarki's broader ad\\-tech infrastructure.\n\n\n**Qualifications \\& Skills:**\n\n\n* 3\\+ years of experience in data engineering, big data processing, or related roles (6\\+ years for Senior Data Engineer role)\n* Strong programming skills in Python, Java, or Scala.\n* Experience with distributed data processing frameworks such as Apache Spark, Flink, or Hadoop.\n* Strong understanding of SQL and NoSQL databases for data storage and retrieval.\n* Experience with real\\-time data streaming technologies like Apache Kafka or Pulsar.\n* Knowledge of containerization and orchestration tools like Docker and Kubernetes is a plus.\n* Strong problem\\-solving skills and ability to work in a fast\\-paced environment.\n* Bachelor's or Master's degree in Computer Science, Engineering, or a related field.\n\n\nIf you're passionate about data engineering and want to work on innovative AI\\-driven advertising solutions, we'd love to hear from you! Apply today.",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE664193.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/664193\/aarki-squareLogo-1713370543302.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009647990258",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009647990258",
        "job_url_direct":null,
        "title":"Developer - GCP & Data Engineer",
        "company":"CGI",
        "location":"Bengaluru",
        "date_posted":1740182400000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":600000.0,
        "max_amount":700000.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"Key Responsibilities:  \n\n* Design and develop scalable data engineering solutions using Google Cloud Platform (GCP) and PySpark.\n* Optimize Spark jobs for performance, scalability, and efficient resource utilization.\n* Develop, maintain, and enhance ETL pipelines using BigQuery, Apache Airflow, and Cloud Composer.\n* Collaborate with data scientists, analysts, and DevOps teams to translate business requirements into technical solutions.\n* Ensure data integrity and security by implementing data governance, compliance, and security best practices.\n* Monitor production workloads, troubleshoot performance issues, and implement enhancements.\n* Implement and enforce coding standards, best practices, and performance tuning strategies.\n* Support migration activities from on\\-premises data warehouses to GCP\\-based solutions.\n* Mentor junior developers and contribute to knowledge\\-sharing within the team.\n* Stay up to date with emerging cloud technologies, tools, and best practices in the data engineering ecosystem.\n\n\nRequired Skills \\& Experience:  \n\n* \u0146\\+ years of total experience in data engineering.\n* \u0144\\+ years of hands\\-on experience with Google Cloud Platform (GCP), including BigQuery, Apache Airflow, and Cloud Composer.\n* Strong expertise in developing and optimizing large\\-scale data processing solutions using Pyspark and Python.\n* In\\-depth knowledge of SQL for data transformation and performance optimization.\n* Proficiency in big data technologies such as Hadoop, HDFS, Hive, and YARN.\n* Experience with distributed computing principles, data partitioning, and fault tolerance.\n* Hands\\-on experience with CI\/CD pipelines, version control (Git), and automation tools.\n* Strong problem\\-solving, analytical, and troubleshooting skills.\n* Experience working in Agile\/Scrum environments.\n* Excellent communication and collaboration skills to work with offshore and onshore teams.\n**Your future duties and responsibilities**\n\n**Required qualifications to be successful in this role**\n\n**Together, as owners, let\u2019s turn meaningful insights into action.**  \n\n  \n\nLife at CGI is rooted in ownership, teamwork, respect and belonging. Here, you\u2019ll reach your full potential because\u2026  \n\n  \n\nYou are invited to be an owner from day 1 as we work together to bring our Dream to life. That\u2019s why we call ourselves CGI Partners rather than employees. We benefit from our collective success and actively shape our company\u2019s strategy and direction.  \n\n  \n\nYour work creates value. You\u2019ll develop innovative solutions and build relationships with teammates and clients while accessing global capabilities to scale your ideas, embrace new opportunities, and benefit from expansive industry and technology expertise.  \n\n  \n\nYou\u2019ll shape your career by joining a company built to grow and last. You\u2019ll be supported by leaders who care about your health and well\\-being and provide you with opportunities to deepen your skills and broaden your horizons.\n  \n\n  \n\nCome join our team\u2014one of the largest IT and business consulting services firms in the world.",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE8452.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/8452\/cgi-squarelogo-1451998175252.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009647990272",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009647990272",
        "job_url_direct":null,
        "title":"Developer - GCP & Data Engineer",
        "company":"CGI",
        "location":"Bengaluru",
        "date_posted":1740182400000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":435000.0,
        "max_amount":780250.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"Key Responsibilities:  \n\n* Design and develop scalable data engineering solutions using Google Cloud Platform (GCP) and PySpark.\n* Optimize Spark jobs for performance, scalability, and efficient resource utilization.\n* Develop, maintain, and enhance ETL pipelines using BigQuery, Apache Airflow, and Cloud Composer.\n* Collaborate with data scientists, analysts, and DevOps teams to translate business requirements into technical solutions.\n* Ensure data integrity and security by implementing data governance, compliance, and security best practices.\n* Monitor production workloads, troubleshoot performance issues, and implement enhancements.\n* Implement and enforce coding standards, best practices, and performance tuning strategies.\n* Support migration activities from on\\-premises data warehouses to GCP\\-based solutions.\n* Mentor junior developers and contribute to knowledge\\-sharing within the team.\n* Stay up to date with emerging cloud technologies, tools, and best practices in the data engineering ecosystem.\n\n\nRequired Skills \\& Experience:  \n\n* \u0146\\+ years of total experience in data engineering.\n* \u0144\\+ years of hands\\-on experience with Google Cloud Platform (GCP), including BigQuery, Apache Airflow, and Cloud Composer.\n* Strong expertise in developing and optimizing large\\-scale data processing solutions using Pyspark and Python.\n* In\\-depth knowledge of SQL for data transformation and performance optimization.\n* Proficiency in big data technologies such as Hadoop, HDFS, Hive, and YARN.\n* Experience with distributed computing principles, data partitioning, and fault tolerance.\n* Hands\\-on experience with CI\/CD pipelines, version control (Git), and automation tools.\n* Strong problem\\-solving, analytical, and troubleshooting skills.\n* Experience working in Agile\/Scrum environments.\n* Excellent communication and collaboration skills to work with offshore and onshore teams.\n**Your future duties and responsibilities**\n\n**Required qualifications to be successful in this role**\n\n**Ensemble, en tant que propri\u00e9taires, mettons notre savoir\\-faire \u00e0 l\u2019\u0153uvre.**  \n\n  \n\nLa vie chez CGI est ancr\u00e9e dans l\u2019actionnariat, le travail d\u2019\u00e9quipe, le respect et un sentiment d\u2019appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que\u2026\n  \n\n  \n\nNous vous invitons \u00e0 devenir propri\u00e9taire d\u00e8s le jour 1 alors que nous travaillons ensemble \u00e0 faire de notre r\u00eave une r\u00e9alit\u00e9. C\u2019est pourquoi nous nous d\u00e9signons comme associ\u00e9s de CGI, plut\u00f4t que comme employ\u00e9s. Nous tirons profit des retomb\u00e9es de notre succ\u00e8s collectif et contribuons activement \u00e0 l\u2019orientation et \u00e0 la strat\u00e9gie de notre entreprise.  \n\n  \n\nVotre travail cr\u00e9e de la valeur. Vous \u00e9laborerez des solutions novatrices et d\u00e9velopperez des relations durables avec vos coll\u00e8gues et clients, tout en ayant acc\u00e8s \u00e0 des capacit\u00e9s mondiales pour concr\u00e9tiser vos id\u00e9es, saisir de nouvelles opportunit\u00e9s, et b\u00e9n\u00e9ficier d\u2019une expertise sectorielle et technologique de pointe.\n  \n\n  \n\nVous ferez \u00e9voluer votre carri\u00e8re en vous joignant \u00e0 une entreprise b\u00e2tie pour cro\u00eetre et durer. Vous serez soutenus par des leaders qui ont votre sant\u00e9 et bien\\-\u00eatre \u00e0 c\u0153ur et qui vous permettront de saisir des occasions afin de parfaire vos comp\u00e9tences et \u00e9largir les horizons.  \n\n  \n\nJoignez\\-vous \u00e0 nous, l\u2019une des plus importantes entreprises de conseil en technologie de l\u2019information (TI) et en management au monde.",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE8452.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/8452\/cgi-squarelogo-1451998175252.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009647359554",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009647359554",
        "job_url_direct":null,
        "title":"Senior Software Engineer Lead - SRE with Devops",
        "company":"Optum",
        "location":"Bengaluru",
        "date_posted":1740182400000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":500000.0,
        "max_amount":850000.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start **Caring. Connecting. Growing together.**\n\n  \n\n\n\n\nOptum AI is UnitedHealth Group\u2019s enterprise AI team. We are AI\/ML scientists and engineers with deep expertise in AI\/ML engineering for health care. We develop AI\/ML solutions for the highest impact opportunities across UnitedHealth Group businesses including UnitedHealthcare, Optum Financial, Optum Health, Optum Insight, and Optum Rx. In addition to transforming the health care journey through responsible AI\/ML innovation, our charter also includes developing and supporting an enterprise AI\/ML development platform.\n\n\n\nOptum AI team members:\n\n\n* Have impact at scale: We have the data and resources to make an impact at scale. When our solutions are deployed, they have the potential to make health care system work better for everyone\n* Do ground\\-breaking work: Many of our current projects involve cutting edge ML, NLP and LLM techniques. Generative AI methods for working with structured and unstructured health care data are continuously being developed and improved. We are working in one of the most important frontiers of AI\/ML research and development\n* Partner with world\\-class experts on innovative solutions: Our team members are developing novel AI\/ML solutions to business challenges. In some cases, this includes the opportunity to file patents and publish papers about the methods we develop. We also collaborate with AI\/ML researchers at some of the world\u2019s top universities.\n\n\nOptum AI is chartered to drive value on high impact enterprise AI problems, democratize AI through the enterprise ML platform, accelerate the adoption of Generative Artificial Intelligence (Gen AI) and drive Responsible AI. Projecting to deliver $8\\.4B of benefit value over the next 5 years through these efforts as well as reduce risk through safe, accurate, and unbiased AI, this is a key focus of the enterprise.\n\n\n**Primary Responsibilities:**\n\n\n* Continuous support: Provide continuous SRE support to thousands of geographically distributed learners on the UAIS platform: respond to tickets, triage support, liaise with customers\n* Automation \\& DevOps: Improve existing Infrastructure as Code (IaC) according to best DevOps practices\n* Systems Monitoring: Develop and maintain monitoring frameworks for UAIS infrastructure in relation to AI\/ML training program\n* Security \\& Compliance: Collaborate with cybersecurity teams to ensure all systems and operations comply with industry standards and are secure against evolving threats\n* Capacity Planning \\& Cost Optimization: Forecast and manage capacity requirements for the AI\/ML training environment, while identifying opportunities to reduce costs without compromising performance\n* Disaster Recovery \\& Business Continuity: Design, test, and implement disaster recovery and business continuity plans to ensure minimal downtime and data integrity\n* Comply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and\/or re\\-assignment to different work locations, change in teams and\/or work shifts, policies in regards to flexibility of work benefits and\/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\n**Required Qualifications:**\n\n\n* Bachelor\u2019s degree in computer science, information technology, or a related field\n* 5\\+ years of infrastructure experience: Proven experience working on large\\-scale, cloud\\-based, enterprise\\-level software platforms and deep understanding of multi\\-cloud architectures, specifically Azure, AWS, and GCP, with hands\\-on experience in cloud management\n* 3\\+ years of practical experience in Infrastructure\\-as\\-Code and CI\/CD tools like Terraform, Git Actions and alike\n* 2\\+ years of practical experience in containerization technologies (Kubernetes, Docker) and orchestration\n* 2\\+ years of practical experience in Scripting \\& Automation Skills: Advanced proficiency in scripting languages such as Python and Bash to support automation and system integration efforts\n\n  \n\n\n*At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age, location and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes \\- an enterprise priority reflected in our mission.*",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE2409113.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/2409113\/optum-squareLogo-1711654052254.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"gd-1009646617994",
        "site":"glassdoor",
        "job_url":"https:\/\/www.glassdoor.com\/job-listing\/j?jl=1009646617994",
        "job_url_direct":null,
        "title":"Senior Data Engineer",
        "company":"Nielsen",
        "location":"Bengaluru",
        "date_posted":1740096000000,
        "job_type":null,
        "salary_source":"direct_data",
        "interval":"yearly",
        "min_amount":640250.0,
        "max_amount":837500.0,
        "currency":"INR",
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":"organic",
        "emails":null,
        "description":"**ABOUT THIS JOB**\nAround here we\u2019re all numbers people, but it\u2019s the 1s and 0s behind our data that make what we\ndo possible. Software engineers strike a balance between precision and disruption, between\nreliability and innovation. Nielsen is a tech company backed by nearly a century of forward\nmomentum to show the world what\u2019s next\u2014and we couldn\u2019t have done it without our engineers.  \n\nIn this role, you will be working alongside data scientists and engineers within Nielsen\u2019s\nMarketing Effectiveness business, to build a data platform on AWS to ingest data from external\nsources and perform ETL tasks. The role requires you to have experience working with large\ndatasets with complex schemas, a can\\-do approach towards automation, with an emphasis on\nthe implementation of best practice cloud security principles.\n### **RESPONSIBILITIES**\n\n* Identify, design, and implement process improvements: automating manual processes,\n* optimizing for usability, re\\-designing for greater scalability\n* Collaborate with product and technology teams to design and validate the capabilities of\n* the data platform\n* Develop, implement and maintain good programming standards and practices across\n* the ecosystem\n* Experience building and optimizing data pipelines in a distributed environment\n* Experience supporting and working with cross\\-functional teams\n* Excellent communication skills and the ability to present complex ideas in a clear and\n* concise manner to a variety of audiences\n\n### **QUALIFICATIONS**\n\n* 4\\+ years of experience programming in Python and SQL\n* 4\\+ years of experience with using a broad range of AWS technologies \\- e.g. S3,\n* Lambda, Glue, Athena, IAM, SQS, CloudWatch, CloudFormation\n* 2\\+ years working knowledge of Apache Superset or Tableau, Spark, Hive and Hadoop\n* Ability to implement application components without detailed guidance\n* Proficiency working in Linux environment\n* Experience using tools such as: Git, Gitlab and Jira\n* The training to back your work: a master\u2019s degree, bachelor\u2019s degree, or, as we\n* recognize there isn\u2019t one formula for success, equivalent work experience\n\n**ABOUT NIELSEN**\nWe\u2019re in tune with what the world is watching, buying, and everything in between. If you can\nthink of it, we\u2019re measuring it. We sift through the small stuff and piece together big pictures to\nprovide a comprehensive understanding of what\u2019s happening now and what\u2019s coming next for\nour clients. Today\u2019s data is tomorrow\u2019s marketplace revelation.  \n\nWe like to be in the middle of the action. That\u2019s why you can find us at work in over 100\ncountries. From global industry leaders to small businesses, consumer goods to media\ncompanies, we work with them all. We\u2019re bringing in data 24\/7 and the possibilities are endless.\nSee what\u2019s next with us at Nielsen:careers.nielsen.com",
        "company_industry":null,
        "company_url":"https:\/\/www.glassdoor.com\/Overview\/W-EI_IE3776.htm",
        "company_logo":"https:\/\/media.glassdoor.com\/sql\/3776\/nielsen-squareLogo-1647366936869.png",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-K5wHqpg0FVPoVkQhAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/en-in.whatjobs.com\/gfj\/94658474?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Senior Research Scientist - Network Security",
        "company":"Trellix",
        "location":"Davanagere, Karnataka",
        "date_posted":1740009600000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Job Title:\n\nSenior Research Scientist - Network Security\n\nAbout Trellix:\n\nTrellix, the trusted CISO ally, is redefining the future of cybersecurity and soulful work. Our comprehensive, GenAI-powered platform helps organizations confronted by today\u2019s most advanced threats gain confidence in the protection and resilience of their operations. Along with an extensive partner ecosystem, we accelerate technology innovation through artificial intelligence, automation, and analytics to empower over 53,000 customers with responsibly architected security solutions.\n\nWe also recognize the importance of closing the 4-million-person cybersecurity talent gap. We aim to create a home for anyone seeking a meaningful future in cybersecurity and look for candidates across industries to join us in soulful work. More at\n\nJob Summary\n\nWe are looking for a Senior Research Scientist to help us build and expand\n\nTrellix Network Detection and Response. The ideal candidate is someone who is passionate about solving real problems by turning cutting edge research into operational production solutions. In this role, you will focus on analyzing network-based attacker behavior and develop innovative solutions to address emerging challenges in the field of networking.\n\nResponsibilities:\nResearch attacker methodologies and develop innovative solutions to identify detection solutions Knowledge on how machine learning can be applied in networking problems Perform data analysis to measure efficacy and identify methodologies to improve existing solutions Forward Looking Research \u2013 Researcher will help develop leading edge prototypes to solve emerging challenges. Threat Analytics \u2013 Leverage threat intelligence from different sources, identify patterns to co-relate and establish the origin and flow of attacks. Drive roadmap for detection efficacy and network research operation\n\nRequirements:\n\nTotal 10years to 15years of experience in network security At least three years direct or equivalent experience in areas of network-based threats and other aspects of cyber attacks.. Strong understanding of networking protocols (e.g., TCP\/IP) and network architecture. Proficiency in programming languages such as Python, C++, or Java. Solid understanding of Wireshark Knowledge of cybersecurity principles and practices Strong analytical, problem-solving, and communication skills\n\nCompany Benefits and Perks:\n\nWe work hard to embrace diversity and inclusion and encourage everyone to bring their authentic selves to work every day. We offer a variety of social programs, flexible work hours and family-friendly benefits to all of our employees.\nRetirement Plans Medical, Dental and Vision Coverage Paid Time Off Paid Parental Leave Support for Community Involvement\n\nWe're serious about our commitment to diversity which is why we prohibit discrimination based on race, color, religion, gender, national origin, age, disability, veteran status, marital status, pregnancy, gender expression or identity, sexual orientation or any other legally protected status.",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-iEidhfLYNW_f-hzTAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.linkedin.com\/jobs\/view\/senior-principal-data-security-engineer-at-autodesk-3984470953?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Senior Principal Data Security Engineer",
        "company":"Autodesk",
        "location":"Chennai, Tamil Nadu",
        "date_posted":1739491200000,
        "job_type":"contract",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Job Requisition ID #\n\n24WD79840\n\nPosition Overview\n\nThis role guides, defines, and implements the overarching technical data protection strategies and partners across multiple functions as a trusted leader to champion and implement leading data security solutions. You will collaborate with other leaders to shape data security strategies across the company and serves a diverse audience that includes developers and end-users. You will play a crucial role in ensuring that Autodesk's systems and services meet the highest data security standards and align with our industry-leading practices and regulatory requirements. We ask that you have expertise in data security, security engineering, and cloud security that will safeguard data across Autodesk. This is hybrid position in Bengaluru, India. You will report to the Senior Director, Information Security Engineering.\n\nResponsibilities\n\u2022 Design and implement, and operationalize solutions to ensure the data security of infrastructure, applications, and system including the selection and deployment of cybersecurity technologies\n\u2022 Oversee data security throughout the entire lifecycle of infrastructure and services, from design to runtime\n\u2022 Create and establish data security standards, best practices, and assurance processes\n\u2022 Build a comprehensive data catalog and implement data governance strategies\n\u2022 Collaborate with TPMs and influence users to define and prioritize backlog related to data protection efforts\n\u2022 Ensure the data security strategy is aligned with business objectives, reviewed for effectiveness\n\u2022 Lead efforts to mature capabilities for data classification and inventory, strengthen security baselines for data protection and handling, and ensure solutions meet rigorous data security and compliance requirements\n\u2022 Research new services and emerging technologies that will further enhance the data security capabilities\n\u2022 Establish security metrics and define KPIs for data protection programs.\n\nMinimum Qualifications\n\u2022 Bachelor's degree in computer science, information security, or a related field (Master's degree preferred)\n\u2022 15+ years of experience in information security with a focus on hands-on security engineering, data protection, enterprise security, cloud security, and solutions architecture\n\u2022 Data Protection Solutions: Proficiency in designing data protection solutions, such as data security posture management (DSPM), data loss prevention (DLP) systems, encryption technologies, and data masking\/anonymization techniques\n\u2022 Familiarity with industry-standard data protection frameworks and best practices\n\u2022 Identity and Access Management (IAM): In-depth knowledge of IAM principles, including user provisioning, authentication, authorization, and privilege management. Hands-On Experience with IAM technologies, such as LDAP, Active Directory, or identity federation protocols (e.g., SAML, OAuth)\n\u2022 Cloud Security: Proficiency in cloud security and experience with cloud service providers (e.g., AWS, Azure, Google Cloud, O365) and SaaS Data Security, knowledge of secure cloud architecture design, cloud data protection mechanisms, and cloud identity and access management (IAM)\n\u2022 Programming and Scripting Experience ( Python, PowerShell, Shell Scripting, Ruby, Go)\n\u2022 Requires a mixture of security and solutions engineering to create and developsystems and services to operationalize data protection technologies\n\u2022 Excel where success hinges on collaborating with multiple partners and aligning teams in making security decisions and implementing solutions\n\nLearn More\n\nAbout Autodesk\n\nWelcome to Autodesk! Amazing things are created every day with our software \u2013 from the greenest buildings and cleanest cars to the smartest factories and biggest hit movies. We help innovators turn their ideas into reality, transforming not only how things are made, but what can be made.\n\nWe take great pride in our culture here at Autodesk \u2013 our Culture Code is at the core of everything we do. Our values and ways of working help our people thrive and realize their potential, which leads to even better outcomes for our customers.\n\nWhen you\u2019re an Autodesker, you can be your whole, authentic self and do meaningful work that helps build a better future for all. Ready to shape the world and your future? Join us!\n\nSalary transparency\n\nSalary is one part of Autodesk\u2019s competitive compensation package. Offers are based on the candidate\u2019s experience and geographic location. In addition to base salaries, we also have a significant emphasis on discretionary annual cash bonuses, commissions for sales roles, stock or long-term incentive cash grants, and a comprehensive benefits package.\n\nDiversity & Belonging\n\nWe take pride in cultivating a culture of belonging and an equitable workplace where everyone can thrive. Learn more here: https:\/\/www.autodesk.com\/company\/diversity-and-belonging\n\nAre you an existing contractor or consultant with Autodesk?\n\nPlease search for open jobs and apply internally (not on this external site).",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-2ZWaOAQjuqreqY7PAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/www.shine.com\/jobs\/security-data-scientist\/arctic-wolf\/16606567?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Security Data Scientist",
        "company":"Arctic Wolf",
        "location":"Karnataka",
        "date_posted":1739404800000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Arctic Wolf, with its unicorn valuation, is the leader in security operations in an exciting and fast-growing industrycybersecurity. We have won countless awards for our excellence in security operations and remain dedicated to providing an industry-leading customer and employee experience.\n\nOur mission is simple: End Cyber Risk. Were looking for a Security Data Scientist to be a part of making this happen.\n\nAbout The Role\n\nData is a critical part of Arctic Wolf Networks mission to solve cyber risk, where we process and analyze hundreds of billions of events every day to look for malicious and risky behaviour. Furthermore, were geeks at heart and are passionate about data and solving cybersecurity problems for our customers. The AI & Data Science team works on analyzing Arctic Wolfs product platforms, internal business challenges, and customer pain points to develop new products and features for our customers.\n\nAs a Security Data Scientist on the AI & Data Science team you will be responsible for developing data-driven solutions leveraging cutting-edge advanced analytics techniques. This involves working closely with engineering, product, operations, and other teams to understand the most important technical and business analytics needs to drive security-centric analytics outcomes. A successful candidate is self-motivated with a passion for excellence and attention to detail.\n\nAs a Security Data Scientist at Arctic Wolf, you will\nAnalyze and correlate complex data from multiple sources.\nPerform exploratory data analysis to gain deeper understanding of the data.\nWork with stakeholders, including domain experts and product, to understand use cases and domain-specific problems and identify opportunities for applying machine learning to drive outcomes.\nDevelop tools and algorithms for generating synthetic data sets.\nDefine KPIs to measure model performance.\nDevelop and test statistical and machine learning models for efficacy and operational impact.\nWrite production quality code and work with other software engineering teams to deploy models into production.\nSupport deployed models as a subject matter expert.\nBe creative and engineer novel features and methods to push beyond our current capabilities.\n\nWe Are Looking For Someone Who Has\nProven track record of a minimum 2+ years of hands-on experiencein the research, data science and engineering around building and shipping machine learning or statistical models that scale to high volumes of data (billions of data points).\nProficiency with Python and SQL.\nExperience using key ML libraries including scikit-learn, tensorflow, pytorch, sparkml.\nExperience with data fusion and data cleansing techniques for creating labelled data sets.\nExperience with developing synthetic data sets using generative and statistical modelling techniques.\nUnderstanding of classical ML and DNN modelling techniques for supervised and unsupervised learning and sequence modelling.\nUnderstanding of 3 of either PGMs, RL, GNN, statistical modelling, or time series modelling.\nUnderstanding of ensembles and multi modal machine learning techniques to solve complex problems.\nFamiliarity of large-scale distributed systems and related technologies such as Spark, Elasticsearch, Kubernetes, etc. is a plus.\nFamiliarity with cloud platforms (we use AWS here) and automation technologies (e.g., Kubernetes, Jenkins, Chef, etc.) is a plus.\nFamiliarity with the information\/cyber security domain is a plus.\n\nAbout Arctic Wolf\n\nAt Arctic Wolf were cultivating a collaborative and productive work environment that welcomes a diversity of backgrounds, cultures, and ideas to make our teams even stronger as we grow globally. Weve been named one of the 50 Most Innovative Companies in the world for 2022 (Fast Company)and the 2nd Most Innovative Security Company. We have won countless awards for our excellence in security operations and remain dedicated to providing an industry-leading customer and employee experience including:\nTop Workday USA (2021-2024)\nGreat Place to Work (2022-2024) & Best Workplaces for Women (2024) in Canada\nBest Workplaces in Tech & For Women in the UK (2023)\nTop Company by Kununu in Germany (2024)\n\nOur Values\n\nArctic Wolf recognizes that success comes from delighting our customers, so we work together to ensure that happens every day. We believe in diversity and inclusion, and truly value the unique qualities and unique perspectives all employees bring to the organization. And we appreciate thatby protecting peoples and organizations sensitive data and seeking to end cyber risk we get to work in an industry that is fundamental to the greater good.\n\nWe celebrate unique perspectives by creating a platform for all voices to be heard through our Pack Unity program. We encourage all employees to join or create a new alliance. See more about our Pack Unity here.\n\nSecurity Requirements\nConducts duties and responsibilities in accordance with AWNs Information Security policies, standards, processes, and controls to protect the confidentiality, integrity and availability of AWN business information (in accordance with our employee handbook and corporate policies).\nBackground checks are required for this position.,",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-36HbPc-byxa3XtNXAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.indeed.com\/viewjob?jk=0ae210a2258aee02&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"I&F-Cyber Security-Investigations & Forensics-Data Analytics -Senior Associate \u2013 Bangalore",
        "company":"PwC",
        "location":"Karnataka",
        "date_posted":1738627200000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Line of Service\nAdvisory\n\nIndustry\/Sector\nNot Applicable\n\nSpecialism\nFraud, Investigations & Regulatory Enforcement (FIRE)\n\nManagement Level\nSenior Associate\n\nJob Description & Summary\nA career in our Cybersecurity, Privacy and Forensics will provide you the opportunity to solve our clients most critical business and data protection related challenges. You will be part of a growing team driving strategic programs, data analytics, innovation, deals, cyber resilency, response, and technical implementation activities. You will have access to not only the top Cybersecurity, Privacy and Forensics professionals at PwC, but at our clients and industry analysts across the globe.\n\nOur Investigations team focuses on helping our clients to detect and investigate fraudulent activities or irregularities within their organisation. As part of our team, you will perform fraud investigations, forensic accounting engagements, litigation support, crisis response, insurance claims support, and address anti-kickback and anti-bribery matters for a diverse group of both public and private multinational clients, not-for profits and state and local governments. You will work closely with the office of general counsel, chief compliance officers, boards and outside counsel. Our team not only helps clients respond to instances of fraud or irregularity, but also works with them to emerge stronger as an entity.\n\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades\/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\n\nAs a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\n\u2022 Use feedback and reflection to develop self awareness, personal strengths and address development areas.\n\u2022 Delegate to others to provide stretch opportunities and coach to help deliver results.\n\u2022 Develop new ideas and propose innovative solutions to problems.\n\u2022 Use a broad range of tools and techniques to extract insights from from current trends in business area.\n\u2022 Review your work and that of others for quality, accuracy and relevance.\n\u2022 Share relevant thought leadership.\n\u2022 Use straightforward communication, in a structured way, when influencing others.\n\u2022 Able to read situations and modify behavior to build quality, diverse relationships.\n\u2022 Uphold the firm's code of ethics and business conduct.\n\nOverview:\nPwC\u2019s Insights & Forensics (I&F) Data Analytics team in the Acceleration Center (AC) is seeking a highly skilled and motivated Senior Associate to join our dynamic team. The ideal candidate will bring technical expertise, innovative thinking, and strong analytical skills to deliver insights and value to our clients. This role demands a hands-on professional who can seamlessly work with cross-functional teams, process large volumes of data, and create impactful visualizations and analytics solutions.\n\nKey Responsibilities:\n\u2022 Data Analysis & Visualization:\n\u2022 Develop and design interactive dashboards, reports, and data visualizations using Power BI and Tableau to provide actionable insights.\n\u2022 Collaborate with stakeholders to gather business requirements and transform them into meaningful visuals and stories.\n\u2022 Data Engineering & Analytics Development:\n\u2022 Utilize Python and PySpark to process, transform, and analyze large datasets efficiently.\n\u2022 Implement advanced SQL queries and Alteryx for complex data manipulation, reporting, and validation.\n\u2022 Cloud Analytics Solutions:\n\u2022 Build, maintain, and optimize analytics workflows using Azure Synapse Analytics and Databricks .\n\u2022 Leverage cloud-based solutions to design scalable data pipelines and integrate disparate data sources.\n\u2022 Collaboration & Delivery:\n\u2022 Partner with US stakeholders and internal teams to understand key business problems and deliver analytics-driven solutions.\n\u2022 Document technical workflows, processes, and best practices to ensure high-quality deliverables and knowledge sharing.\n\nRequired Skills & Qualifications:\n\u2022 Technical Proficiency:\n\u2022 Expert-level knowledge and hands-on experience with Power BI for data visualization and reporting.\n\u2022 Proficient in programming with Python and working with distributed computing frameworks like PySpark .\n\u2022 Strong command of Advanced SQL and Alteryx for data analysis and manipulation across relational databases.\n\u2022 Demonstrated expertise in working with Azure Synapse Analytics and Databricks for building cloud-based data solutions.\n\u2022 Problem-Solving & Analytical Thinking:\n\u2022 Strong ability to analyze complex business problems and translate them into data-driven solutions.\n\u2022 Creative mindset with a focus on delivering value through innovative approaches to analytics and visualization.\n\u2022 Communication & Collaboration:\n\u2022 Excellent verbal and written communication skills for engaging with stakeholders and explaining technical concepts.\n\u2022 Ability to work independently and collaboratively within a team, ensuring high standards of delivery.\n\u2022 Education & Experience:\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Data Analytics, Information Systems, or a related field.\n\u2022 5-7 years of relevant experience in data analytics, data engineering, or business intelligence roles.\n\u2022 Experience in professional services or consulting is a plus.\n\nGood to Have Skills:\n\u2022 Experience in Prompt Engineering and working with Generative AI (GenAI) solutions.\n\u2022 Knowledge of Data Science concepts and methodologies.\n\u2022 Familiarity with Machine Learning techniques and frameworks.\n\u2022 Education & Experience:\n\u2022 Bachelor\u2019s or Master\u2019s degree in Data Science, Data Analytics, Information Systems, or a related field.\n\u2022 5-7 years of relevant experience in data analytics, data engineering, or business intelligence roles.\n\u2022 Experience in professional services or consulting is a plus.\n\nEducation (if blank, degree and\/or field of study not specified)\nDegrees\/Field of Study required:\n\nDegrees\/Field of Study preferred:\n\nCertifications (if blank, certifications not specified)\n\nRequired Skills\n\nOptional Skills\nAccepting Feedback, Accepting Feedback, Active Listening, Analytical Thinking, Communication, Compliance Oversight, Compliance Risk Assessment, Corporate Governance, Creativity, Cybersecurity, Data Analytics, Debt Restructuring, Embracing Change, Emotional Regulation, Empathy, Evidence Gathering, Financial Crime Compliance, Financial Crime Investigation, Financial Crime Prevention, Financial Record Keeping, Financial Transactions, Forensic Accounting, Forensic Investigation, Fraud Detection, Fraud Investigation {+ 12 more}\n\nDesired Languages (If blank, desired languages not specified)\n\nTravel Requirements\nNot Specified\n\nAvailable for Work Visa Sponsorship?\nNo\n\nGovernment Clearance Required?\nNo",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-AWk_RNH2T0hHGR0eAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.indeed.com\/viewjob?jk=e2681ad498a13fa2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"CyberSecurity Data Scientist, Account and Device Intelligence",
        "company":"Google",
        "location":"Karnataka",
        "date_posted":1737936000000,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Minimum qualifications:\n\u2022 Bachelor's degree or equivalent practical experience.\n\u2022 2 years of experience in data analysis, including identifying trends, generating summary statistics, and drawing insights from quantitative and qualitative data.\n\u2022 2 years of experience managing projects and defining project scope, goals, and deliverables.\n\nPreferred qualifications:\n\u2022 Master's degree or PhD in Computer Science, Engineering, Mathematics, Physics or a related technical field.\n\u2022 Experience in large-scale data analysis and related tools and processes.\n\u2022 Experience in automating processes or applied AI.\n\u2022 Knowledge in account security, network engineering, malware or artificial intelligence.\n\nAbout the job\n\nIn this role, you will be working with a team of analysts that assess and address threats against Google accounts. You will identify and solve complex issues at scale and have investigative and technical skills. You will be proactive, motivated, organized, responsible, innovative and are able to work well in a fluid, global, cross-functional, and team-oriented environment and demonstrate technical know-how, effective communication to get things done. You will also work very closely with engineering teams and product teams to make sure that new products and features provide a good, safe experience for users. You will build, leverage and evaluate ML\/AI models to solve cybersecurity and abuse issues.\nAt Google we work hard to earn our users\u2019 trust every day. Trust Safety is Google\u2019s team of abuse fighting and user trust experts working daily to make the internet a safer place. We partner with teams across Google to deliver bold solutions in abuse areas such as malware, spam and account hijacking. A diverse team of Analysts, Policy Specialists, Engineers, and Program Managers, we work to reduce risk and fight abuse across all of Google\u2019s products, protecting our users, advertisers, and publishers across the globe in over 40 languages.\n\nResponsibilities\n\u2022 Provide high-quality, detailed and actionable qualitative and quantitative understanding of the threat landscape, designing and improving additional data collection, processes and quality measures.\n\u2022 Design and build early warning alerts for novel and changing account threats, based on researching, understanding and experimenting with attacker operations and attacker interactions with our systems.\n\u2022 Provide and apply our threat intelligence to be ready to respond to new adversarial campaigns.\n\u2022 Lead incident response to incidents efforts for Google, including the special response in case of severe incidents in collaboration with the UP\/Account and Device Intelligence (ADI) team.\n\u2022 Work together with our GOC team (located in Hyderabad) to scale the operational work required to protect Google accounts, such as handling low severity escalations and alerts, and maintaining the ground truth quality. Provide the training and work with UP\/ADI.\n\nGoogle is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See alsoGoogle's EEO Policy andEEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing ourAccommodations for Applicants form.",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"go-uP4dTKO0NyWjuk3cAAAAAA==",
        "site":"google",
        "job_url":"https:\/\/in.indeed.com\/viewjob?jk=67ac630aad3ecc54&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",
        "job_url_direct":null,
        "title":"Lead Product Consultant : Network Automation + Cloud architect + Data Scientist",
        "company":"Juniper Networks",
        "location":"Karnataka",
        "date_posted":null,
        "job_type":null,
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":false,
        "job_level":null,
        "job_function":null,
        "listing_type":null,
        "emails":null,
        "description":"Job Description\n\nAt Juniper, we believe the network is the single greatest vehicle for knowledge, understanding, and human advancement the world has ever known.\n\nTo achieve real outcomes, we know that experience is the most important requirement for networking teams and the people they serve. Delivering an experience-first, AI-Native Network pivots on the creativity and commitment of our people. It requires a consistent and committed practice, something we call the Juniper Way.\n\nPosition: Lead Product Consultant : Network Automation + Cloud architect + Data Scientist\n\nLocation: Bangalore\n\nExperience: 12+ years\n\nAbout Team :The services automation team aims to use AI and automation to solve Customer's business problems. All customers have unique challenges. This team understands the customers challenges, identifies ways to optimise solution delivery, proposes solution based on customer technology needs and delivers them with quality in a timely manner. The most interesting aspect of the role is, each customer solution brings unique challenges and hence the role requires continuous technical upskilling based on market trends.\n\nResponsibilities:\n\u2022 Work in a consultative manner with consultants, product managers, customers, system engineering, support, sales and customer services to scope the work and deliver projects.\n\u2022 Run requirements and scoping workshops with the stake holders, delivery partners, and sales.\n\u2022 Involved in solution deployments, network Automation and implementations.\n\u2022 Evaluate customer solutions for performance, scalability, and security and provide feedback.\n\u2022 Develop and maintain an in-depth technical knowledge of the Juniper Networks products. Work with the internal Juniper Networks technical teams for placement of products and feature improvements for reliability, availability, and serviceability.\n\u2022 Develop advanced ML\/AI models leveraging both structured and unstructured datasets for batch and online inferencing use cases within the Customer services domain.\n\u2022 Collaborate with partners including the executive, product, data, and operations teams to transform business priorities into ML\/AI problems and develop solutions.\n\u2022 Work with MLOps specialists to manage the full life cycle of model development from concept to production.\n\u2022 Collaborate with data and analytics specialists to strive for greater functionality in our data systems.\n\u2022 Identify trends and patterns from datasets to scope opportunities for automation.\n\u2022 Work closely with colleagues and customer personnel to help design, test, automate and plan for deployments of new products and features.\n\u2022 Support Customer in the early stages of solution deployment.\n\u2022 Provide appropriate training (Knowledge Transfer workshops) to Juniper Networks partners and customers.\n\u2022 Reviewing customer provided (technical) information\n\u2022 Providing input related to \u2018best practices\u2019 in solution design, implementation, deployment planning, and validation & verification testing\n\u2022 Taking ownership of, or assisting with creating Assessment, High-Level Design, Low-Level Design. Test Plans and Implementation.\n\nPreferred Qualifications\n\u2022 Strong architecture skills, design and implementation experience.\n\u2022 Experience in Microservices, domain-driven design and event-driven architectures.\n\u2022 Strong JUNOS skills and excellent hands-on planning capabilities.\n\u2022 Excellent and deep hands-on experience in designing \/ architecting large scale software solutions.\n\u2022 Deep hands-on in developing software products\/projects in object-oriented Python.\n\u2022 Sound knowledge of SOLID principles, GoF patterns, cloud-native design patterns and experience in Designing Multi-cloud Environments.\n\u2022 Architecting and developing secure solutions in public cloud environments such as AWS\/Azure.\n\u2022 Strong experience in container-based Cloud Management Platforms (Kubernetes & OpenShift), Kafka, Prometheus, Redis, ELK stack and NoSQL databases.\n\u2022 Sound knowledge in Networking concepts. Good understanding of networking virtualization in Private clouds - VMware ESXi or OpenStack.\n\u2022 Hands on experience in DevOps, GitHub, Code Coverage and Unit Testing. Working experience in GIT & JENKINS \/ GitLab and strong knowledge of branching strategies.\n\u2022 Experience working with Large Language Models, Generative AI, and Conversational AI. Familiarity with one or more machine learning or statistical modeling tools such as Numpy, ScikitLearn, MLlib, Tensorflow, and NLP libraries.\n\u2022 Create and maintain optimal data pipeline architecture, assembling large, sophisticated data sets that meet functional\/non-functional business requirements.\n\u2022 Sound knowledge in Ansible, Yang, XML, JINJA & Yaml\n\u2022 Should have Network Automation fundamentals. Network Management and Telco Cloud exposure is preferable.\n\u2022 Good Knowledge in Inventory tool such as NetBox \/ Netcracker.\n\u2022 Expertise in coding best practices and secure coding practices is essential.\n\u2022 Excellent written and verbal communication skills. The candidate will be involved in leading projects and hence good leadership skills are essential.\n\u2022 Commitment to delivering a remarkable customer experience.\n\nExperience\/Background Desired:\n\u2022 12+ years\u2019 overall experience, preferably with Networking background.\n\u2022 4+ years of experience in end-to-end architecting of advanced ML and AI solutions. Strong hands-on coding skills (preferably in Python) for processing large-scale data sets and developing machine learning models leveraging both structured and unstructured data.\n\u2022 Hands-on experience on Juniper devices will be a plus.\n\nJuniper is an Equal Opportunity workplace and Affirmative Action employer. We do not discriminate in employment decisions on the basis of race, colour, religion, gender (including pregnancy), national origin, political affiliation, sexual orientation, gender identity or expression, marital status, disability, genetic information, age, veteran status, or any other applicable legally protected characteristic. All employment decisions are made on the basis of individual qualifications, merit, and business need.\n\nABOUT JUNIPER NETWORKS\n\nJuniper Networks challenges the inherent complexity that comes with networking and security in the multicloud era. We do this with products, solutions and services that transform the way people connect, work and live. We simplify the process of transitioning to a secure and automated multicloud environment to enable secure, AI-driven networks that connect the world. Additional information can be found at Juniper Networks (www.juniper.net) or connect with Juniper on Twitter, LinkedIn and Facebook.\n\nWHERE WILL YOU DO YOUR BEST WORK?\n\nWherever you are in the world, whether it's downtown Sunnyvale or London, Westford or Bangalore, Juniper is a place that was founded on disruptive thinking - where colleague innovation is not only valued, but expected. We believe that the great task of delivering a new network for the next decade is delivered through the creativity and commitment of our people. The Juniper Way is the commitment to all our colleagues that the culture and company inspire their best work-their life's work. At Juniper we believe this is more than a job - it's an opportunity to help change the world...\n\nINCLUSION AND DIVERSITY AT JUNIPER\n\nAt Juniper Networks, we are committed to elevating talent by creating a trust-based environment where we can all thrive together. We know from experience that people from underrepresented groups often do not apply for roles they do not feel they meet all the criteria for. If you think you have what it takes, but do not necessarily check every single box, please consider applying. We\u2019d love to speak with you.\n\nAdditional Information for United States jobs:\n\nELIGIBILITY TO WORK AND E-VERIFY\n\nIn compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.\n\nJuniper Networks participates in the E-Verify program. E-Verify is an Internet-based system operated by the Department of Homeland Security (DHS) in partnership with the Social Security Administration (SSA) that allows participating employers to electronically verify the employment eligibility of new hires and the validity of their Social Security Numbers.\n\u2022 Information for applicants about E-Verify \/ E-Verify Informaci\u00f3n en espa\u00f1ol: This Company Participates in E-Verify \/ Este Empleador Participa en E-Verify\n\u2022 Immigrant and Employee Rights Section (IER) - The Right to Work \/ El Derecho a Trabajar\n\nE-Verify\u00ae is a registered trademark of the U.S. Department of Homeland Security.\n\nJuniper is an Equal Opportunity workplace and Affirmative Action employer. We do not discriminate in employment decisions on the basis of race, color, religion, gender (including pregnancy), national origin, political affiliation, sexual orientation, gender identity or expression, marital status, disability, genetic information, age, veteran status, or any other applicable legally protected characteristic. All employment decisions are made on the basis of individual qualifications, merit, and business need.",
        "company_industry":null,
        "company_url":null,
        "company_logo":null,
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4160070812",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4160070812",
        "job_url_direct":null,
        "title":"Software Development Engineering Testing",
        "company":"Deloitte",
        "location":"Bangalore Urban, Karnataka, India",
        "date_posted":1740182400000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"not applicable",
        "job_function":"Information Technology and Consulting",
        "listing_type":null,
        "emails":null,
        "description":"**Your potential, unleashed** \n\n\n\n\n  \n\n\n\n\n\n India\u2019s impact on the global economy has increased at an exponential rate and Deloitte presents an opportunity to unleash and realise your potential amongst cutting edge leaders, and organisations shaping the future of the region, and indeed, the world beyond.\n \n\n\n\n  \n\n\n\n\n\n At Deloitte, you bring your whole self to work every day. Combine that with our drive to propel with purpose and you have the perfect playground to collaborate, innovate, grow, and make an impact that matters.\n \n\n\n\n  \n\n\n\n\n\n**The team** \n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n Innovation, transformation and leadership occur in many ways. At Deloitte, our ability to help solve clients\u2019 most complex issues is distinct. We deliver strategy and implementation, from a business and technology view, to help you lead in the markets where you compete.\n \n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n**Your work profile** \n\n\n\n\n  \n\n\n\n\n\n**SDET(Software Development Engineering Testing)** \n\n\n\n\n  \n\n\n\n\n\n Programming Proficiency: Strong knowledge of programming languages such as Java, Python, or JavaScript for writing automation scripts.\n \n\n\n\n  \n\n\n\n\n* Testing Tools Familiarity: Experience with automation tools like Selenium, JUnit, or TestNG is essential for effective test execution.\n* Analytical Skills: Ability to analyze complex software systems and identify potential weaknesses or areas for improvement.\n* Attention to Detail: A meticulous approach to testing procedures ensures high\\-quality outcomes.\n* Communication Skills: Excellent verbal and written communication skills are necessary for collaboration with cross\\-functional teams.\n* QA Automation Engineer\\- Strong Java, Selenium, Cucumber BDD, Serenity,\n* REST Assured API Automation testing, SQL skills, Salesforce automation experience.\n\n\n\n  \n\n\n\n\n\n**Desired qualifications** \n\n\n\n\n  \n\n\n\n\n* Minimum 6 plus years of experience\n* SDET\\- Strong Java, Selenium, Cucumber BDD, Serenity,\n* REST Assured API Automation testing, SQL skills, Strong Knowledge on advance Java concepts(Lambda functions,Java Streams, Table parser concepts)\n* Good to have: Agile, JIRA\n\n\n\n  \n\n\n\n\n\n**Location and way of working** \n\n\n\n\n  \n\n\n\n\n* Base location: Mumbai \/ Pune \/ Delhi \/ Bengaluru \/ Hyderabad \/ Chennai \/ Bhubaneshwar\n* This profile involves occasional travelling to client location.\n* Hybrid is our default way of working. Each domain has customised the hybrid approach to their unique needs.\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n**Your role as an Assistant Manager** \n\n\n\n\n  \n\n\n\n\n\n We expect our people to embrace and live our purpose by challenging themselves to identify issues that are most important for our clients, our people, and for society.\n \n\n\n\n  \n\n\n\n\n\n In addition to living our purpose, Assistant Manager\/Deputy Manager across our organization must strive to be:\n \n\n\n\n  \n\n\n\n\n* Inspiring \\- Leading with integrity to build inclusion and motivation\n* Committed to creating purpose \\- Creating a sense of vision and purpose\n* Agile \\- Achieving high\\-quality results through collaboration and Team unity\n* Skilled at building diverse capability \\- Developing diverse capabilities for the future\n* Persuasive \/ Influencing \\- Persuading and influencing stakeholders\n* Collaborating \\- Partnering to build new solutions\n* Delivering value \\- Showing commercial acumen\n* Committed to expanding business \\- Leveraging new business opportunities\n* Analytical Acumen \\- Leveraging data to recommend impactful approach and solutions through the power of analysis and visualization\n* Effective communication \u2013 Must be well abled to have well\\-structured and well\\-articulated conversations to achieve win\\-win possibilities\n* Engagement Management \/ Delivery Excellence \\- Effectively managing engagement(s) to ensure timely and proactive execution as well as course correction for the success of engagement(s)\n* Managing change \\- Responding to changing environment with resilience\n* Managing Quality \\& Risk \\- Delivering high quality results and mitigating risks with utmost integrity and precision\n* Strategic Thinking \\& Problem Solving \\- Applying strategic mindset to solve business issues and complex problems\n* Tech Savvy \\- Leveraging ethical technology practices to deliver high impact for clients and for Deloitte\n* Empathetic leadership and inclusivity \\- creating a safe and thriving environment where everyone's valued for who they are, use empathy to understand others to adapt our behaviours and attitudes to become more inclusive.\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n**How you\u2019ll grow** \n\n\n\n\n  \n\n\n\n\n\n***Connect for impact***\n\n\n\n\n  \n\n\n\n\n\n Our exceptional team of professionals across the globe are solving some of the world\u2019s most complex business problems, as well as directly supporting our communities, the planet, and each other. Know more in our Global Impact Report and our India Impact Report.\n \n\n\n\n  \n\n\n\n\n\n***Empower to lead***\n\n\n\n\n  \n\n\n\n\n\n You can be a leader irrespective of your career level. Our colleagues are characterised by their ability to inspire, support, and provide opportunities for people to deliver their best and grow both as professionals and human beings. Know more about Deloitte and our One Young World partnership.\n \n\n\n\n  \n\n\n\n\n\n***Inclusion for all***\n\n\n\n\n  \n\n\n\n\n\n At Deloitte, people are valued and respected for who they are and are trusted to add value to their clients, teams and communities in a way that reflects their own unique capabilities. Know more about everyday steps that you can take to be more inclusive. At Deloitte, we believe in the unique skills, attitude and potential each and every one of us brings to the table to make an impact that matters.\n \n\n\n\n  \n\n\n\n\n\n***Drive your career***\n\n\n\n\n  \n\n\n\n\n\n At Deloitte, you are encouraged to take ownership of your career. We recognise there is no one size fits all career path, and global, cross\\-business mobility and up \/ re\\-skilling are all within the range of possibilities to shape a unique and fulfilling career. Know more about Life at Deloitte.\n \n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n**Everyone\u2019s welcome\u2026 entrust your happiness to us** \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Our workspaces and initiatives are geared towards your 360\\-degree happiness. This includes specific needs you may have in terms of accessibility, flexibility, safety and security, and caregiving. Here\u2019s a glimpse of things that are in store for you.",
        "company_industry":"Software Development, IT System Testing and Evaluation, and IT Services and IT Consulting",
        "company_url":"https:\/\/www.linkedin.com\/company\/deloitte",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C560BAQGNtpblgQpJoQ\/company-logo_100_100\/company-logo_100_100\/0\/1662120928214\/deloitte_logo?e=2147483647&v=beta&t=OSF8M5LreT0Sf2F-JcNk6XMT0ArCuPfDmRR-knCC4HY",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4159069695",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4159069695",
        "job_url_direct":null,
        "title":"Data Scientist",
        "company":"Synechron",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":1740096000000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"mid-senior level",
        "job_function":"Information Technology",
        "listing_type":null,
        "emails":null,
        "description":"Good day,\n \n\n\n\n  \n\n\n\n\n\n We have immediate opportunity for\n **Data Scientist** \n role\n \n \u2013 7 to 10 years.\n \n\n\n\n  \n\n\n\n\n\n**Job Role Data Scientist** \n\n\n\n\n**Job Location: Bangalore** \n\n\n\n\n**Experience\\-** \n 7\\+\n \n\n\n\n**Notice Period: Immediate** \n\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n**About Company:** \n\n\n\n\n At Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry\\-leading digital solutions. Synechron\u2019s progressive technologies and optimization strategies span end\\-to\\-end Artificial Intelligence, Consulting, Digital, Cloud \\& DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile\\-first applications and more. Over the last 20\\+ years, our company has been honoured with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,700\\+, and has 52 offices in 20 countries within key global markets. For more information on the company, please visit our website or LinkedIn community.\n \n\n\n\n  \n\n\n\n\n\n**Diversity, Equity, and Inclusion** \n\n\n\n\n  \n\n\n\n\n\n Diversity \\& Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and an affirmative\\-action employer. Our Diversity, Equity, and Inclusion (DEI) initiative \u2018Same Difference\u2019 is committed to fostering an inclusive culture \u2013 promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.\n \n\n\n\n All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant\u2019s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.\n \n\n\n\n  \n\n\n\n\n\n**Job Description** \n :\n **Data Scientist** \n\n\n\n\n  \n\n\n\n\n\n As a\n **Data Scientist** \n you will be at the forefront of designing and developing applications with a focus on cloud\\-native solutions.\n \n\n\n\n  \n\n\n\n\n\n**Key Responsibilities:** \n\n\n\n* Design, develop, and implement Knowledge Graph solutions that meet business requirements.\n* Utilize graph databases such as AWS Neptune, Neo4j, and Nebula to create and manage Knowledge Graphs.\n* Work with graph formats including RDF and Property Graph, and perform graph queries using SPARQL and openCypher.\n* Collaborate with cross\\-functional teams to integrate Knowledge Graphs into existing systems and applications.\n* Leverage experience with Large Language Models (LLMs) and frameworks to enhance Knowledge Graph capabilities.\n* Ensure data quality, integrity, and security within the Knowledge Graph.\n* Stay updated with the latest advancements in AI and Knowledge Graph technologies.\n\n\n\n**Must Have:** \n\n\n\n* Proven experience in building Knowledge Graph solutions using graph databases (e.g., AWS Neptune, Neo4j, Nebula).\n* Familiarity with graph formats, including RDF and Property Graph, and proficiency in graph querying with SPARQL and openCypher.\n* Prior experience working with Large Language Models (LLMs) and related frameworks.\n* Strong knowledge of cloud computing, with a preference for AWS.\n* Proficient in programming languages such as Python, Java, and TypeScript.\n* Excellent problem\\-solving skills and attention to detail.\n* Strong communication and collaboration skills to work effectively within a team.\n\n\n\n  \n\n\n\n\n\n  \n\n\n\n\n\n With below details (Mandatory)\n \n\n\n\n Total Experience\n \n\n\n\n Experience in Skills\\- Gen AI, AWS\n \n\n\n\n Experience in Skills\\- Python\/Java\n \n\n\n\n Current CTC\\-\n \n\n\n\n Expected CTC\\-\n \n\n\n\n Notice period\\-\n \n\n\n\n Current Location\\-(Bangalore\/Pune)\n \n\n\n\n  \n\n\n\n\n\n If you had gone through any interviews in Synechron before? If Yes when\n \n\n\n\n  \n\n\n\n\n\n Regards,\n \n\n\n\n TAG",
        "company_industry":"Financial Services",
        "company_url":"https:\/\/www.linkedin.com\/company\/synechron",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C4D0BAQF-kdmTYpOKFg\/company-logo_100_100\/company-logo_100_100\/0\/1663673608492\/synechron_logo?e=2147483647&v=beta&t=PADKlIbUyh1lHoIIbBvjT5Acs9QF3fcqvBoeJ-t9AQc",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4035187281",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4035187281",
        "job_url_direct":"https:\/\/pwc.wd3.myworkdayjobs.com\/Global_Experienced_Careers\/job\/Bengaluru-Millenia\/Associate_525454WD-2\/?source=LinkedIn&urlHash=T8fY",
        "title":"Associate",
        "company":"PwC India",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":1740096000000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"mid-senior level",
        "job_function":"Other",
        "listing_type":null,
        "emails":null,
        "description":"**Line of Service**\n Advisory\n   \n\n  \n\n**Industry\/Sector**\n Not Applicable\n   \n\n  \n\n**Specialism**\n Data, Analytics \\& AI\n   \n\n  \n\n**Management Level**\n Associate\n   \n\n  \n\n**Job Description \\& Summary**\n A career within Data and Analytics services will provide you with the opportunity to help organisations uncover enterprise insights and drive business results using smarter data analytics. We focus on a collection of organisational technology capabilities, including business intelligence, data management, and data assurance that help our clients drive innovation, growth, and change within their organisations in order to keep up with the changing nature of customers and technology. We make impactful decisions by mixing mind and machine to leverage data, understand and navigate risk, and help our clients gain a competitive edge.\n   \n\n  \n\n Creating business intelligence from data requires an understanding of the business, the data, and the technology used to store and analyse that data. Using our Rapid Business Intelligence Solutions, data visualisation and integrated reporting dashboards, we can deliver agile, highly interactive reporting and analytics that help our clients to more effectively run their business and understand what business questions can be answered and how to unlock the answers.\n   \n\n  \n\n Broad Role \/ Responsibilities We are seeking a highly skilled and motivated Data Engineer Developer with 3 to 5 years of experience\n   \n\n  \n\n to join our dynamic team. The ideal candidate must have strong hands\\-on expertise in technologies such as Spark, Scala, Hadoop,\n   \n\n  \n\n SQL, and demonstrated exposure to Azure cloud services. The Data Engineer Developer will play a crucial role in designing,\n   \n\n  \n\n implementing, and maintaining robust data pipelines, ensuring the efficient flow and processing of large datasets.\n   \n\n  \n\n* Data Pipeline Development: Design, develop, and maintain scalable and efficient data pipelines using Spark and Scala. Implement ETL processes for ingesting, transforming, and loading data from various sources.\n* Big Data Technologies: Work with Hadoop ecosystem components such as HDFS, Hive, and HBase for efficient storage and retrieval of large\\-scale datasets. Optimize and tune Spark jobs to ensure optimal performance and resource utilization.\n* SQL Expertise: Utilize strong SQL skills to query, analyse, and manipulate data stored in relational databases and data warehouses.\n* Security \\- Implement security and data protection measures, at all levels \u2013 DB, API services. Apply Data masking and row\\-level and column\\-level security. Keep abreast of latest security issues and incorporate necessary patches and updates.\n* Testing and Debugging \\- Write and maintain test code to validate functionality. Debug applications and troubleshoot issues as they arise.\n* Collaboration and Communication \\- Collaborate with cross\\-functional teams including Database engineers, data integration engineers, reporting teams and product development. Communicate complex data findings in a clear and actionable manner to non\\-technical stakeholders.\n* Continual Learning\\- Keep up to date with emerging tools, techniques, and technologies in data technologies. Engage in self\\-improvement and continuous learning opportunities to maintain expertise in the data science domain.\n* End to end understanding of project and infrastructure involving multiple technologies (Big Data Analytics)\n* Proactively identify problem areas \\& concerns related to data in the project; exploration of ways to tackle the issues and come\\-up with optimal solutions.\n* Creation of FRS\/SRS\/Design documents and other technical documents.\n* Prepare \u201clessons learned\u201d documentation for projects \/ engagements. Develop best practices and tools for project execution and\n\n\n management. Nice to Have:\n   \n\n  \n\n* Exposure to Azure Cloud.\n* Experience of working in Travel and logistics domain is preferred.\n* Familiarity with data streaming technologies (e.g., Apache Kafka).\n* Exposure to containerization and orchestration tools (e.g., Docker, Kubernetes).\n* Knowledge of machine learning concepts and frameworks.\n\n\n Mandatory skill sets\\-\n **Scala, Spark**\n**Year Of Experience Required\\- 3\\-5**\n Qualifications\\-\n **B.E \/B.Tech \/ MBA\/MCA**\n**Education** \n*(if blank, degree and\/or field of study not specified)*\n**Degrees\/Field Of Study Required**\n Degrees\/Field of Study preferred:\n   \n\n  \n\n**Certifications** \n*(if blank, certifications not specified)*\n**Required Skills**\n Apache Spark, Scala (Programming Language)\n   \n\n  \n\n**Optional Skills**\n**Desired Languages** \n*(If blank, desired languages not specified)*\n**Travel Requirements**\n**Available for Work Visa Sponsorship?**\n**Government Clearance Required?**\n**Job Posting End Date**",
        "company_industry":"Business Consulting and Services",
        "company_url":"https:\/\/in.linkedin.com\/company\/pwc-india",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/D560BAQFYf1IhPukA5Q\/company-logo_100_100\/company-logo_100_100\/0\/1719912934875\/pwc_india_logo?e=2147483647&v=beta&t=C7FShWuDFc2twP4u8aW9jUbkShzPr_ceL6Mf_G5Dx7I",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4119785274",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4119785274",
        "job_url_direct":"https:\/\/jobs.exxonmobil.com\/ExxonMobil\/job\/Bengaluru-Physical-Data-Scientist-KA\/1248728800\/?feedId=223600&utm_source=LinkedInJobPostings&utm_campaign=EOM_Linkedin&urlHash=aiMK",
        "title":"Physical Data Scientist",
        "company":"ExxonMobil",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":1740096000000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"mid-senior level",
        "job_function":"Engineering",
        "listing_type":null,
        "emails":null,
        "description":"**About Us**\n At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net\\-zero future. As one of the world\u2019s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.\n   \n\n  \n\n The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower\\-emissions technologies.\n   \n\n  \n\n We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society\u2019s evolving needs. Learn more about\n **our What and our Why** \n and how we can work\n **together** \n .\n   \n\n  \n\n**What Role You Will Play In Our Team**\n Develop, deploy, sustain and support software technologies for oilfield production optimization using data\\-driven or physics\\-based methods.\n   \n\n  \n\n**What You Will Do**\n* Develop high quality software code (C\\#, Matlab, Python) using best practices for software development \\& agile methodologies.\n* Refactor legacy code \\& leverage testing frameworks to ensure sustainability and maintainability of the product\n* Collaborate with engineers and operators on global teams to understand business needs for technology development.\n* Collaborate with cross disciplinary team of SMEs and computational scientists to identify opportunities \\& build solutions for upstream oil and gas business.\n\n\n**About You**\n**Skills and Qualifications**\n* Master\u2019s degree from a recognized university in Petroleum \/ Chemical \/ Mechanical \/ Civil \/ Aerospace or any other engineering disciplines with minimum GPA 7\\.0\n* Minimum 3 years of experience in Oil \\& Gas Industry\n* Experience with mathematical modeling, scientific computing and numerical methods\n* Experience with programming\/scripting languages like C\\+\\+\/C\\# or Matlab\/Python\n\n\n**Preferred Qualifications \/ Experience**\n* Experience with Agile development practices is a plus\n* Experience with Azure Cloud and Databricks is a plus\n* Experience with oil \\& gas industry\n\n\n**Your Benefits**\n An ExxonMobil career is one designed to last. Our commitment to you runs deep our employees grow personally and professionally, with benefits built on our core categories of health, security, finance and life. We offer you:\n   \n\n  \n\n* Competitive compensation\n* Medical plans, maternity leave and benefits, life, accidental death and dismemberment benefits\n* Retirement benefits\n* Global networking \\& cross\\-functional opportunities\n* Annual vacations \\& holidays\n* Day care assistance program\n* Training and development program\n* Tuition assistance program\n* Workplace flexibility policy\n* Relocation program\n* Transportation facility\n\n\n Please note benefits may change from time to time without notice, subject to applicable laws. The benefits programs are based on the Company\u2019s eligibility guidelines.\n   \n\n  \n\n**Stay connected with us**\n* Learn more about ExxonMobil in India, visit ExxonMobil India and Energy Factor India.\n* Follow us on LinkedIn and ExxonMobil (@exxonmobil)\n * Instagram photos and videos\n* Like us on Facebook\n* Subscribe our channel at YouTube\n**EEO Statement**\n ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin or disability status.\n   \n\n  \n\n**Business solicitation and recruiting scams**\n ExxonMobil does not use recruiting or placement agencies that charge candidates an advance fee of any kind (e.g., placement fees, immigration processing fees, etc.). Follow the LINK to understand more about recruitment scams in the name of ExxonMobil.\n   \n\n  \n\n Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship.\n   \n\n  \n\n Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co\\-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.",
        "company_industry":"Oil and Gas",
        "company_url":"https:\/\/www.linkedin.com\/company\/exxonmobil",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C4D0BAQE_IRWZ2qVHpw\/company-logo_100_100\/company-logo_100_100\/0\/1631303598129?e=2147483647&v=beta&t=20NshSkLIzCoKGk7fkNxWckGM7OnZQ5_ddDzZ5Pcwqk",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    },
    {
        "id":"li-4160541811",
        "site":"linkedin",
        "job_url":"https:\/\/www.linkedin.com\/jobs\/view\/4160541811",
        "job_url_direct":"https:\/\/careers.microsoft.com\/us\/en\/job\/1798403\/Software-Engineer?jobsource=linkedin&utm_source=Job%20Board&utm_campaign=linkedin-feed&urlHash=yd1y",
        "title":"Software Engineer",
        "company":"Microsoft",
        "location":"Bengaluru, Karnataka, India",
        "date_posted":1740009600000,
        "job_type":"fulltime",
        "salary_source":null,
        "interval":null,
        "min_amount":null,
        "max_amount":null,
        "currency":null,
        "is_remote":null,
        "job_level":"not applicable",
        "job_function":"Engineering and Information Technology",
        "listing_type":null,
        "emails":null,
        "description":"Microsoft Azure Storage is a highly distributed, massively scalable, and ubiquitously accessible cloud storage platform. To provide unmatched performance at lowest cost and power, the Azure storage team is building the storage stack that will run on the DPU (Data Processing Units) based storage nodes. We are looking for a Software Engineer who is interested in developing and deploying distributed storage.\n   \n\n  \n\n As a Software Engineer, you will have a chance to work on design, implementation, and optimizations of highly performant and massively scale out storage on DPU hardware. You will be involved in all phases of the storage lifecycle, design, implementation, test, deployment, and support. This opportunity will allow you to accelerate your career growth and hone your technical skills.\n   \n\n  \n\n Microsoft\u2019s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.\n   \n\n  \n\n**Responsibilities**\n* Works with appropriate stakeholders to determine user requirements for the new features to be developed.\n* Participates and contributes to the design of massively scalable storage services\n* Owns software components and\/or modules and drives the component level design decisions working with the team, senior engineers, and architects.\n* Creates and implements code for a product, service, or feature, reusing code as applicable. Writes and learns to create code that is extensible and maintainable.\n* Considers diagnosability, reliability, and maintainability with few defects, and understands when the code is ready to be shared and delivered.\n* Works in a culture of continuous improvement, adaptation, reflection, and growth.\n\n\n**Qualifications**\n**Required Qualifications:**\n* Bachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C\\+\\+, C\\#, Java, JavaScript, or Python.\n+ OR equivalent experience.\n\n\n**Other Requirements**\n* Ability to meet Microsoft, customer and\/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire\/transfer and every two years thereafter.\n\n\n**Additional \/ Preferred Qualifications**\n* Bachelor's Degree in Computer Science or related technical field AND 1\\+ year(s) technical engineering experience with coding in languages including, but not limited to, C, C\\+\\+, C\\#, Java, JavaScript, or Python\n* OR Master's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C\\+\\+, C\\#, Java, JavaScript, or Python\n* OR equivalent experience.\n* Knowledge of Windows or Linux Operating System, AND distributed systems and storage.\n\n\n \\#Azurecorejobs\n   \n\n  \n\n Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and\/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
        "company_industry":"Software Development",
        "company_url":"https:\/\/www.linkedin.com\/company\/microsoft",
        "company_logo":"https:\/\/media.licdn.com\/dms\/image\/v2\/C560BAQE88xCsONDULQ\/company-logo_100_100\/company-logo_100_100\/0\/1630652622688\/microsoft_logo?e=2147483647&v=beta&t=lMkCSsceJNmUG1r0VRg3Whye1sVi2KtYvt-MWyfoNbY",
        "company_url_direct":null,
        "company_addresses":null,
        "company_num_employees":null,
        "company_revenue":null,
        "company_description":null
    }
]